"""
æ¨ç†å±‚ï¼ˆModel Orchestratorï¼‰ï¼š
æ ¹æ® OPTIMIZATION_NOTES.md çš„äº”å±‚æ¶æ„è®¾è®¡

èŒè´£ï¼š
- è°ƒç”¨å¤šä¸ªå¤§æ¨¡å‹ APIï¼ˆé€šè¿‡ç»Ÿä¸€æ¥å£ AICanAPIï¼‰
- æ”¯æŒçš„æ¨¡å‹ï¼šGPT-4oã€Claudeã€Geminiã€Grokã€Qwenã€DeepSeek ç­‰
- å¹¶å‘è°ƒç”¨å¤šä¸ªæ¨¡å‹ï¼Œæé«˜æ•ˆç‡
- è§£ææ¨¡å‹è¿”å›çš„å†…å®¹ï¼šåˆ¤æ–­å€¾å‘ã€ç†ç”±è¯´æ˜ã€ä¸»è§‚æ¦‚ç‡
- ä» config/models.json è¯»å–æ¨¡å‹é…ç½®
- æ”¯æŒè‡ªåŠ¨é™çº§æœºåˆ¶

è¾“å…¥ï¼šå„æ¨¡å‹çš„ promptï¼ˆå­—ç¬¦ä¸²ï¼‰
è¾“å‡ºï¼šå„æ¨¡å‹çš„é¢„æµ‹ç»“æœ {probability, confidence, reasoning}
"""
import aiohttp
import asyncio
import json
import math
import os
import re
import time
import traceback
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dotenv import load_dotenv

load_dotenv()

# å„æ¨¡å‹è‡ªé€‚åº”è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰- åŸºäºå®é™…APIå“åº”é€Ÿåº¦
MODEL_TIMEOUTS = {
    "gpt-4o": 30,
    "claude-3-7-sonnet-latest": 50,
    "claude-3.7-sonnet": 50,
    "claude-opus-4-1": 50,
    "gemini-2.5-pro": 45,
    "gemini-2.5-flash": 40,
    "grok-4": 60,
    "grok-3": 55,
    "deepseek-chat": 35,
}


class ModelOrchestrator:
    """
    Orchestrates parallel calls to multiple AI models via AICanAPI.
    
    ç®¡ç†å¤šä¸ªAIæ¨¡å‹çš„å¹¶å‘è°ƒç”¨ï¼š
    - é€šè¿‡ AICanAPI ç»Ÿä¸€æ¥å£è°ƒç”¨ä¸åŒæ¨¡å‹
    - æ”¯æŒæ¨¡å‹æƒé‡é…ç½®
    - è§£æ JSON æ ¼å¼çš„é¢„æµ‹ç»“æœ
    - é”™è¯¯å¤„ç†å’Œè¶…æ—¶æ§åˆ¶
    - ä» config/models.json è¯»å–é…ç½®
    - æ”¯æŒè‡ªåŠ¨é™çº§æœºåˆ¶
    """
    
    # å„æ¨¡å‹è‡ªé€‚åº”è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰- æ ¹æ®å®é™…APIå“åº”é€Ÿåº¦è°ƒæ•´
    MODEL_TIMEOUTS = {
        "gpt-4o": 30,
        "claude-3-7-sonnet-latest": 50,
        "claude-opus-4-1": 50,
        "claude-3-5-opus-latest": 50,
        "gemini-2.5-pro": 45,
        "gemini-2.5-flash": 40,
        "grok-4": 60,  # Grokå“åº”è¾ƒæ…¢ï¼Œç»™æ›´å¤šæ—¶é—´
        "grok-3": 60,
        "deepseek-chat": 35,
    }
    
    # å…¼å®¹æ—§çš„å¸¸é‡ï¼ˆä½¿ç”¨æœ€å¤§è¶…æ—¶ä½œä¸ºé»˜è®¤å€¼ï¼‰
    SINGLE_MODEL_TIMEOUT = 60  # é»˜è®¤è¶…æ—¶ï¼ˆä½¿ç”¨æœ€å¤§æ¨¡å‹çš„è¶…æ—¶ï¼‰
    PARALLEL_CALLS_TIMEOUT = 90  # å¹¶è¡Œè°ƒç”¨æ€»è¶…æ—¶ï¼ˆè€ƒè™‘é‡è¯•ï¼‰
    MAX_TOTAL_WAIT_TIME = 90  # æœ€å¤§æ€»ç­‰å¾…æ—¶é—´ï¼ˆåŒ…æ‹¬é‡è¯•å’Œé™çº§ï¼‰
    
    # é‡è¯•é…ç½®
    MAX_RETRIES = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
    RETRY_DELAY_BASE = 5  # åŸºç¡€é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    RETRY_DELAY_MAX = 10  # æœ€å¤§é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    
    # å¹¶å‘æ§åˆ¶
    MAX_CONCURRENT_MODELS = 2  # åŒæ—¶æœ€å¤šè¿è¡Œçš„æ¨¡å‹æ•°ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
    
    # ç®€æ˜“ Platt Scaling å‚æ•°ï¼ˆæ ¹æ®ç¦»çº¿æ ¡å‡†ç»“æœï¼Œå¯åœ¨é…ç½®ä¸­è°ƒæ•´ï¼‰
    PLATT_PARAMS = {
        "gpt-4o": {"A": -1.15, "B": 0.25},
        "claude-3-7-sonnet-latest": {"A": -1.05, "B": 0.18},
        "gemini-2.5-pro": {"A": -0.95, "B": 0.10},
        "grok-4": {"A": -1.20, "B": 0.35},
        "deepseek-chat": {"A": -0.85, "B": 0.05},
        "default": {"A": 0.0, "B": 0.0}
    }
    
    def __init__(self):
        """Initialize ModelOrchestrator and load model configurations from JSON."""
        self.models_config = self._load_models_config()
        self.MODELS = self._build_models_dict()
        self.active_models = {}  # Track actually used models (with fallback handling)
        # å¹¶å‘æ§åˆ¶ä¿¡å·é‡ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡ MODEL_MAX_CONCURRENCY è°ƒæ•´
        concurrency_limit = int(os.getenv("MODEL_MAX_CONCURRENCY", self.MAX_CONCURRENT_MODELS))
        self._concurrency_semaphore = asyncio.Semaphore(max(1, concurrency_limit))
        self.current_concurrency_limit = max(1, concurrency_limit)
        self._log_model_versions()
    
    def _load_models_config(self) -> Dict:
        """Load model configurations from config/models.json."""
        config_path = Path(__file__).parent.parent / "config" / "models.json"
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return config
        except FileNotFoundError:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
            print("   ä½¿ç”¨é»˜è®¤é…ç½®...")
            return self._get_default_config()
        except json.JSONDecodeError as e:
            print(f"âš ï¸ é…ç½®æ–‡ä»¶è§£æé”™è¯¯: {e}")
            print("   ä½¿ç”¨é»˜è®¤é…ç½®...")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict:
        """Return default configuration if JSON file is not available."""
        return {
            "models": {
                "gpt-4o": {
                    "display_name": "GPT-4o",
                    "model_id": "gpt-4o",
                    "source": "aicanapi",
                    "api_key_env": "AICANAPI_KEY",
                    "weight": 3.0,
                    "is_default": True,
                    "fallback": None,
                    "last_updated": "2024-11-21"
                }
            },
            "api_endpoints": {
                "aicanapi": "https://aicanapi.com/v1/chat/completions",
                "deepseek": "https://api.deepseek.com/v1/chat/completions"
            }
        }
    
    def _build_models_dict(self) -> Dict:
        """Build MODELS dict from JSON configuration, filtering enabled models."""
        models_dict = {}
        api_endpoints = self.models_config.get("api_endpoints", {})
        enabled_models = []
        disabled_models = []
        
        for model_key, model_config in self.models_config.get("models", {}).items():
            # Check if model is enabled (default to True for backward compatibility)
            if not model_config.get("enabled", True):
                disabled_models.append(model_config.get("display_name", model_config.get("model_id", model_key)))
                # Skip disabled models and their fallbacks
                continue
                
            model_id = model_config["model_id"]
            source = model_config["source"]
            url = api_endpoints.get(source, "")
            
            enabled_models.append(model_config.get("display_name", model_id))
            
            models_dict[model_id] = {
                "display_name": model_config.get("display_name", model_id),
                "source": source,
                "url": url,
                "api_key_env": model_config["api_key_env"],
                "weight": model_config["weight"],
                "fallback": model_config.get("fallback"),
                "fallback_display_name": model_config.get("fallback_display_name"),
                "last_updated": model_config.get("last_updated", "æœªçŸ¥"),
                "is_default": model_config.get("is_default", False)
            }
            
            # Add fallback model if exists (only if primary model is enabled)
            if model_config.get("fallback"):
                fallback_id = model_config["fallback"]
                models_dict[fallback_id] = {
                    "display_name": model_config.get("fallback_display_name", fallback_id),
                    "source": source,
                    "url": url,
                    "api_key_env": model_config["api_key_env"],
                    "weight": model_config["weight"] * 0.9,  # Slightly lower weight for fallback
                    "fallback": None,
                    "last_updated": model_config.get("last_updated", "æœªçŸ¥"),
                    "is_default": False
                }
        
        # Print confirmation log
        if enabled_models:
            enabled_str = ", ".join(enabled_models)
            print(f"[DEBUG] Active models: {enabled_str}")
        if disabled_models:
            disabled_str = ", ".join(disabled_models)
            print(f"[DEBUG] Disabled models: {disabled_str}")
        
        return models_dict
    
    def _log_model_versions(self):
        """Log current model versions."""
        active_versions = []
        for model_key, model_config in self.models_config.get("models", {}).items():
            display_name = model_config.get("display_name", model_key)
            active_versions.append(display_name)
        
        versions_str = " / ".join(active_versions)
        print(f"ğŸ“Š å½“å‰ä½¿ç”¨æ¨¡å‹ç‰ˆæœ¬: {versions_str}")
    
    def get_model_info(self, model_name: str) -> Optional[Dict]:
        """Get model information including display name and version."""
        if model_name in self.MODELS:
            return {
                "model_id": model_name,
                "display_name": self.MODELS[model_name].get("display_name", model_name),
                "last_updated": self.MODELS[model_name].get("last_updated", "æœªçŸ¥"),
                "weight": self.MODELS[model_name].get("weight", 1.0)
            }
        
        # Check if it's a fallback model
        for config in self.models_config.get("models", {}).values():
            if config.get("fallback") == model_name:
                return {
                    "model_id": model_name,
                    "display_name": config.get("fallback_display_name", model_name),
                    "last_updated": config.get("last_updated", "æœªçŸ¥"),
                    "weight": self.MODELS.get(model_name, {}).get("weight", 1.0) if model_name in self.MODELS else 1.0
                }
        
        return None
    
    def get_active_models_summary(self) -> Dict[str, Dict]:
        """Get summary of all active models with their versions."""
        summary = {}
        for model_name in self.MODELS.keys():
            info = self.get_model_info(model_name)
            if info:
                summary[model_name] = info
        return summary
    
    def _get_model_timeout(self, model_name: str) -> float:
        """
        è·å–æ¨¡å‹çš„è‡ªé€‚åº”è¶…æ—¶æ—¶é—´
        
        Args:
            model_name: æ¨¡å‹åç§°
        
        Returns:
            è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        # å°è¯•ç²¾ç¡®åŒ¹é…
        if model_name.lower() in self.MODEL_TIMEOUTS:
            return self.MODEL_TIMEOUTS[model_name.lower()]
        
        # å°è¯•éƒ¨åˆ†åŒ¹é…ï¼ˆä¾‹å¦‚ "claude-3-7-sonnet-latest" åŒ¹é… "claude"ï¼‰
        model_lower = model_name.lower()
        for key, timeout in self.MODEL_TIMEOUTS.items():
            if key in model_lower or model_lower in key:
                return timeout
        
        # é»˜è®¤è¶…æ—¶
        return 40.0
    
    async def _call_single_model(self, model_name: str, prompt: str) -> Optional[Dict]:
        """
        å•æ¬¡æ¨¡å‹è°ƒç”¨ï¼ˆä¸åŒ…å«é‡è¯•é€»è¾‘ï¼‰
        
        Args:
            model_name: æ¨¡å‹åç§°
            prompt: æç¤ºè¯
        
        Returns:
            æ¨¡å‹å“åº”ç»“æœæˆ–None
        """
        return await self._call_model_internal(model_name, prompt)
    
    def _get_model_timeout(self, model_name: str) -> float:
        """
        è·å–æ¨¡å‹çš„è‡ªé€‚åº”è¶…æ—¶æ—¶é—´
        
        Args:
            model_name: æ¨¡å‹åç§°
        
        Returns:
            è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        # å°è¯•ç²¾ç¡®åŒ¹é…
        if model_name in MODEL_TIMEOUTS:
            return MODEL_TIMEOUTS[model_name]
        
        # å°è¯•å°å†™åŒ¹é…
        model_lower = model_name.lower()
        for key, timeout in MODEL_TIMEOUTS.items():
            if key.lower() in model_lower or model_lower in key.lower():
                return timeout
        
        # é»˜è®¤è¶…æ—¶
        return self.SINGLE_MODEL_TIMEOUT
    
    def _get_platt_params(self, model_name: str) -> Dict[str, float]:
        return self.PLATT_PARAMS.get(model_name, self.PLATT_PARAMS.get("default", {"A": 0.0, "B": 0.0}))
    
    def _platt_scale_probability(self, model_name: str, probability: float) -> float:
        """Apply Platt scaling to model probability to improve calibration."""
        params = self._get_platt_params(model_name)
        normalized = max(0.001, min(0.999, probability / 100.0))
        logit = math.log(normalized / (1 - normalized))
        logistic_input = params["A"] * logit + params["B"]
        try:
            scaled = 1 / (1 + math.exp(-logistic_input))
        except OverflowError:
            scaled = 0.0 if logistic_input < 0 else 1.0
        return round(max(0.0, min(1.0, scaled)) * 100.0, 2)
    
    def _apply_probability_calibration(self, model_name: str, result: Optional[Dict]) -> Optional[Dict]:
        if not result or "probability" not in result:
            return result
        calibrated = dict(result)
        raw_prob = calibrated.get("probability", 50.0)
        calibrated_prob = self._platt_scale_probability(model_name, raw_prob)
        calibrated["raw_probability"] = raw_prob
        calibrated["probability"] = calibrated_prob
        params = self._get_platt_params(model_name)
        calibrated["calibration"] = {
            "method": "platt",
            "A": params.get("A", 0.0),
            "B": params.get("B", 0.0)
        }
        return calibrated
    
    async def call_model(self, model_name: str, prompt: str, max_retries: int = None) -> Optional[Dict]:
        """
        è°ƒç”¨å•ä¸ªæ¨¡å‹ï¼ˆå¸¦è‡ªé€‚åº”è¶…æ—¶ + é‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            model_name: æ¨¡å‹åç§°
            prompt: æç¤ºè¯
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ä½¿ç”¨ç±»é…ç½®ï¼‰
        
        Returns:
            Dict with 'probability', 'confidence', 'reasoning', or None on error
        """
        if max_retries is None:
            max_retries = self.MAX_RETRIES
        
        timeout_seconds = self._get_model_timeout(model_name)
        start_time = time.time()
        
        print(f"[DEBUG] Calling {model_name} (timeout={timeout_seconds}s, max_retries={max_retries})")
        
        for attempt in range(max_retries):
            attempt_start = time.time()
            try:
                # ä½¿ç”¨ asyncio.wait_for å®ç°è¶…æ—¶æ§åˆ¶ï¼ˆå…¼å®¹æ‰€æœ‰Pythonç‰ˆæœ¬ï¼‰
                result = await asyncio.wait_for(
                    self._call_model_internal(model_name, prompt),
                    timeout=timeout_seconds
                )
                elapsed = time.time() - start_time
                
                if result:
                    print(f"[DEBUG] âœ… {model_name} completed in {elapsed:.2f}s (attempt {attempt+1})")
                    return self._apply_probability_calibration(model_name, result)
                else:
                    print(f"[DEBUG] âš ï¸ {model_name} returned None (attempt {attempt+1}/{max_retries})")
                    
            except asyncio.TimeoutError:
                attempt_elapsed = time.time() - attempt_start
                total_elapsed = time.time() - start_time
                print(f"[TIMEOUT] âš ï¸ {model_name} attempt {attempt+1}/{max_retries} exceeded {timeout_seconds}s (actual: {attempt_elapsed:.2f}s, total: {total_elapsed:.2f}s)")
                
                if attempt < max_retries - 1:
                    # è®¡ç®—é‡è¯•å»¶è¿Ÿï¼ˆé€’å¢ï¼š5s, 8s, 10sï¼‰
                    wait_time = min(self.RETRY_DELAY_BASE * (attempt + 1), self.RETRY_DELAY_MAX)
                    print(f"[RETRY] Retrying {model_name} after {wait_time}s (attempt {attempt+2}/{max_retries})...")
                    await asyncio.sleep(wait_time)
                else:
                    print(f"[FAIL] âŒ {model_name} failed after {max_retries} attempts (timeout).")
                    # è¿”å›ä½ç½®ä¿¡åº¦ç»“æœï¼Œç¡®ä¿æµç¨‹ä¸ä¸­æ–­
                    return self._apply_probability_calibration(model_name, {
                        "probability": 50.0,
                        "confidence": "low",
                        "reasoning": f"Timeout after {max_retries} attempts (last attempt exceeded {timeout_seconds}s)"
                    })
                    
            except Exception as e:
                attempt_elapsed = time.time() - attempt_start
                total_elapsed = time.time() - start_time
                print(f"[ERROR] {model_name} exception on attempt {attempt+1}/{max_retries}: {type(e).__name__}: {e} (elapsed: {attempt_elapsed:.2f}s)")
                traceback.print_exc()
                
                if attempt < max_retries - 1:
                    wait_time = min(3, self.RETRY_DELAY_BASE)  # å¼‚å¸¸æ—¶ä½¿ç”¨è¾ƒçŸ­å»¶è¿Ÿ
                    print(f"[RETRY] Retrying {model_name} after {wait_time}s (attempt {attempt+2}/{max_retries})...")
                    await asyncio.sleep(wait_time)
                else:
                    print(f"[FAIL] âŒ {model_name} failed after {max_retries} attempts (exception).")
                    return self._apply_probability_calibration(model_name, {
                        "probability": 50.0,
                        "confidence": "low",
                        "reasoning": f"Exception after {max_retries} attempts: {type(e).__name__}: {str(e)[:100]}"
                    })
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ˆä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œï¼Œå› ä¸ºä¸Šé¢å·²ç»returnäº†ï¼‰
        total_elapsed = time.time() - start_time
        print(f"[DEBUG] {model_name} total elapsed {total_elapsed:.2f}s (all attempts failed)")
        return self._apply_probability_calibration(model_name, {
            "probability": 50.0,
            "confidence": "low",
            "reasoning": "All retry attempts failed"
        })
    
    async def _call_model_internal(self, model_name: str, prompt: str) -> Optional[Dict]:
        """Internal method to call a model API with detailed logging."""
        if model_name not in self.MODELS:
            print(f"[DEBUG] {model_name} not in MODELS dict, skipping")
            return None
        
        config = self.MODELS[model_name]
        api_key = os.getenv(config["api_key_env"], "")
        
        # è¯¦ç»†æ—¥å¿—ï¼šAPI keyæ£€æŸ¥
        has_api_key = bool(api_key)
        print(f"[DEBUG] Start calling {model_name}")
        print(f"[DEBUG] {model_name} prompt length: {len(prompt)}")
        print(f"[DEBUG] {model_name} API key loaded: {has_api_key}")
        print(f"[DEBUG] {model_name} request started at: {time.time():.2f}")
        
        if not api_key:
            print(f"âš ï¸ [ERROR] No API key for {model_name}, skipping")
            return None
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        # AICanAPI and DeepSeek use OpenAI-compatible API format
        # Determine model identifier based on source
        if config["source"] == "deepseek":
            # DeepSeek official API uses "deepseek-chat" as model name
            model_identifier = "deepseek-chat"
        else:
            # AICanAPI uses the model_name as identifier
            model_identifier = model_name
        
        payload = {
            "model": model_identifier,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.7,
            "max_tokens": 1200
        }
        
        # è®°å½•è¯·æ±‚å¼€å§‹æ—¶é—´
        request_start_time = time.time()
        display_name = config.get("display_name", model_name)
        url = config.get("url", "")
        
        print(f"[DEBUG] {model_name} URL: {url}")
        print(f"[DEBUG] {model_name} Model identifier: {model_identifier}")
        
        try:
            print(f"ğŸ“¡ Calling {display_name} ({model_name}) at {url}")
            
            # ä½¿ç”¨ç¡¬æ€§è¶…æ—¶æ§åˆ¶
            async with aiohttp.ClientSession() as session:
                try:
                    async with session.post(
                        url,
                        json=payload,
                        headers=headers,
                        timeout=aiohttp.ClientTimeout(total=self.SINGLE_MODEL_TIMEOUT)
                    ) as response:
                        response_time = time.time() - request_start_time
                        print(f"[DEBUG] {model_name} received response at: {time.time():.2f} (took {response_time:.2f}s)")
                        if response.status == 200:
                            parse_start = time.time()
                            data = await response.json()
                            content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                            print(f"âœ… {display_name} responded: {content[:100]}...")
                            result = self._parse_model_response(content)
                            parse_time = time.time() - parse_start
                            
                            total_time = time.time() - request_start_time
                            print(f"[DEBUG] {model_name} parse time: {parse_time:.2f}s, total: {total_time:.2f}s")
                            
                            if result:
                                print(f"âœ… {display_name} parsed successfully: prob={result.get('probability')}%")
                            else:
                                print(f"âš ï¸ {display_name} response parsing failed")
                            return result
                        else:
                            error_text = await response.text()
                            total_time = time.time() - request_start_time
                            print(f"âŒ [ERROR] API error for {display_name}: {response.status} (took {total_time:.2f}s)")
                            print(f"Error details: {error_text[:500]}")
                            return None
                except asyncio.TimeoutError:
                    total_time = time.time() - request_start_time
                    print(f"â±ï¸ [TIMEOUT] {display_name} took too long, returning default. (>{self.SINGLE_MODEL_TIMEOUT}s, actual: {total_time:.2f}s)")
                    # è¿”å›é»˜è®¤å€¼è€Œä¸æ˜¯Noneï¼Œè®©ç³»ç»Ÿå¯ä»¥ç»§ç»­
                    return {
                        "probability": 50.0,
                        "confidence": "low",
                        "reasoning": f"Timeout after {total_time:.2f}s"
                    }
                except aiohttp.ClientError as e:
                    total_time = time.time() - request_start_time
                    print(f"ğŸŒ [ERROR] Network error calling {display_name}: {type(e).__name__}: {e} (took {total_time:.2f}s)")
                    return None
                except Exception as e:
                    total_time = time.time() - request_start_time
                    print(f"âŒ [ERROR] Unexpected error in {display_name} request: {type(e).__name__}: {e} (took {total_time:.2f}s)")
                    import traceback
                    traceback.print_exc()
                    return None
        except asyncio.TimeoutError:
            total_time = time.time() - request_start_time
            print(f"â±ï¸ [TIMEOUT] {display_name} outer timeout (>{self.SINGLE_MODEL_TIMEOUT}s, actual: {total_time:.2f}s)")
            return {
                "probability": 50.0,
                "confidence": "low",
                "reasoning": f"Timeout after {total_time:.2f}s"
            }
        except Exception as e:
            total_time = time.time() - request_start_time
            print(f"âŒ [ERROR] Outer exception calling {display_name}: {type(e).__name__}: {e} (took {total_time:.2f}s)")
            import traceback
            traceback.print_exc()
            return None
    
    def _parse_model_response(self, content: str) -> Optional[Dict]:
        """Parse JSON response from model."""
        if not content or not content.strip():
            print("âš ï¸ Empty response content")
            return None
            
        try:
            # Try to extract JSON from response
            original_content = content
            content = content.strip()
            
            # Look for JSON block
            if "```json" in content:
                start = content.find("```json") + 7
                end = content.find("```", start)
                if end != -1:
                    content = content[start:end].strip()
            elif "```" in content:
                start = content.find("```") + 3
                end = content.find("```", start)
                if end != -1:
                    content = content[start:end].strip()
            
            # Try to find JSON object
            start_brace = content.find("{")
            end_brace = content.rfind("}")
            if start_brace != -1 and end_brace != -1 and end_brace > start_brace:
                content = content[start_brace:end_brace + 1]
            
            # Try to parse JSON
            data = json.loads(content)
            
            # Validate and normalize
            prob = float(data.get("probability", 50.0))
            prob = max(0.0, min(100.0, prob))  # Clamp to [0, 100]
            
            confidence = data.get("confidence", "medium").lower()
            if confidence not in ["low", "medium", "high"]:
                confidence = "medium"
            
            reasoning_candidates = [
                data.get("reasoning_long"),
                data.get("reasoning_short"),
                data.get("reasoning")
            ]
            reasoning = next((r for r in reasoning_candidates if r), None)
            if reasoning:
                reasoning = self._safe_shorten_reasoning(reasoning)
            else:
                reasoning = ""
            return {
                "probability": prob,
                "confidence": confidence,
                "reasoning": reasoning,
                "reasoning_short": data.get("reasoning_short"),
                "reasoning_long": data.get("reasoning_long")
            }
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON decode error: {e}")
            print(f"Content preview: {original_content[:300]}")
            # Try to extract probability from text if JSON parsing fails
            prob_match = re.search(r'probability["\s:]+(\d+\.?\d*)', original_content, re.IGNORECASE)
            if prob_match:
                try:
                    prob = float(prob_match.group(1))
                    prob = max(0.0, min(100.0, prob))
                    print(f"âœ… Extracted probability from text: {prob}%")
                    recovered = self._extract_sentences(original_content)
                    print(f"[PARSE] recovered_unstructured (len={len(recovered)})")
                    return {
                        "probability": prob,
                        "confidence": "medium",
                        "reasoning": recovered,
                        "reasoning_short": None,
                        "reasoning_long": None
                    }
                except:
                    pass
            return None
        except Exception as e:
            print(f"âš ï¸ Error parsing model response: {e}")
            print(f"Content preview: {original_content[:300]}")
            recovered = self._extract_sentences(original_content)
            if recovered:
                print(f"[PARSE] recovered_unstructured (len={len(recovered)})")
                return {
                    "probability": 50.0,
                    "confidence": "medium",
                    "reasoning": recovered,
                    "reasoning_short": None,
                    "reasoning_long": None
                }
            return None

    @staticmethod
    def _safe_shorten_reasoning(text: str, limit: int = 800) -> str:
        text = text.strip()
        if len(text) <= limit:
            return text
        sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ.!?])\s+', text)
        shortened = []
        total_len = 0
        for sentence in sentences:
            if not sentence:
                continue
            sentence_len = len(sentence)
            if total_len + sentence_len > limit:
                break
            shortened.append(sentence)
            total_len += sentence_len
        shortened_text = " ".join(shortened).strip()
        if not shortened_text.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')):
            shortened_text += "..."
        return shortened_text

    @staticmethod
    def _extract_sentences(text: str, limit: int = 3) -> str:
        sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ.!?])\s+', text.strip())
        cleaned = [s.strip() for s in sentences if s.strip()]
        selected = cleaned[:limit]
        joined = " ".join(selected)
        if selected and not selected[-1].endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')):
            joined += "..."
        return joined
    
    async def call_all_models(self, prompts: Dict[str, str]) -> Dict[str, Optional[Dict]]:
        """
        å¹¶å‘è°ƒç”¨æ‰€æœ‰æ¨¡å‹ï¼Œå¹¶åœ¨ MAX_TOTAL_WAIT_TIME åå–æ¶ˆæœªå®Œæˆä»»åŠ¡ã€‚
        """
        overall_start_time = time.time()
        model_names = list(prompts.keys())
        print(f"\n[DEBUG] ========== call_all_models START ==========")
        print(f"[DEBUG] Total models: {len(model_names)} | Max concurrent: {self.current_concurrency_limit}")
        
        semaphore = self._concurrency_semaphore
        default_response = {
            "probability": 50.0,
            "confidence": "low",
            "reasoning": "No response received"
        }

        # [FIX] Guard against empty model batches so asyncio.wait isn't invoked with no tasks.
        if not model_names:
            print("[WARN] No active models to call.")
            return {}
        
        async def guarded_call(model_name: str) -> Tuple[str, Optional[Dict]]:
            async with semaphore:
                call_start = time.time()
                per_model_budget = self._get_model_timeout(model_name) + 10
                try:
                    result = await asyncio.wait_for(
                        self.call_model(model_name, prompts[model_name]),
                        timeout=per_model_budget
                    )
                    call_duration = time.time() - call_start
                    print(f"[DEBUG] {model_name} finished in {call_duration:.2f}s")
                    return model_name, result
                except asyncio.TimeoutError:
                    call_duration = time.time() - call_start
                    print(f"â±ï¸ [WARNING] {model_name} exceeded guarded timeout ({per_model_budget}s). Cancelling task.")
                    return model_name, {
                        "probability": 50.0,
                        "confidence": "low",
                        "reasoning": f"Guarded timeout after {call_duration:.2f}s"
                    }
                except Exception as e:
                    call_duration = time.time() - call_start
                    print(f"âŒ [ERROR] æ¨¡å‹è°ƒç”¨å¼‚å¸¸ â€“ {model_name}: {type(e).__name__}: {e} (took {call_duration:.2f}s)")
                    traceback.print_exc()
                    return model_name, {
                        "probability": 50.0,
                        "confidence": "low",
                        "reasoning": f"Exception: {type(e).__name__}"
                    }
        
        tasks = [asyncio.create_task(guarded_call(name)) for name in model_names]
        # [FIX] Double-check tasks list because filters above might drop every model.
        if not tasks:
            print("[WARN] No active models to call.")
            return {}
        results_dict: Dict[str, Optional[Dict]] = {}
        
        done, pending = await asyncio.wait(
            tasks,
            timeout=self.MAX_TOTAL_WAIT_TIME,
            return_when=asyncio.ALL_COMPLETED
        )
        
        if pending:
            print(f"â±ï¸ [WARNING] å–æ¶ˆ {len(pending)} ä¸ªæœªå®Œæˆçš„æ¨¡å‹è°ƒç”¨ï¼ˆæ€»è¶…æ—¶ {self.MAX_TOTAL_WAIT_TIME}sï¼‰")
            for task in pending:
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass
        
        for task in done:
            try:
                model_name, result = task.result()
                base = result or default_response.copy()
                results_dict[model_name] = self._apply_probability_calibration(model_name, base)
            except Exception as e:
                print(f"âŒ [ERROR] æ”¶é›†æ¨¡å‹ç»“æœå¤±è´¥: {type(e).__name__}: {e}")
                import traceback
                traceback.print_exc()
                # Identify associated model if possible
                model_name = "unknown"
                results_dict[model_name] = self._apply_probability_calibration(model_name, default_response.copy())
        
        for model_name in model_names:
            if model_name not in results_dict:
                results_dict[model_name] = self._apply_probability_calibration(model_name, default_response.copy())
                print(f"âš ï¸ [WARNING] æ¨¡å‹ {model_name} æœªè¿”å›ç»“æœï¼Œä½¿ç”¨é»˜è®¤å€¼")
        
        success_count = sum(1 for r in results_dict.values() if r)
        total_duration = time.time() - overall_start_time
        print(f"[DEBUG] Total execution time: {total_duration:.2f}s | Success: {success_count}/{len(model_names)}")
        print(f"[DEBUG] ========== call_all_models END ==========")
        
        return results_dict
    
    def get_model_weight(self, model_name: str) -> float:
        """Get weight for a model in fusion."""
        return self.MODELS.get(model_name, {}).get("weight", 1.0)
    
    def get_available_models(self) -> List[str]:
        """Get list of models that have API keys configured."""
        available = []
        for model_name, config in self.MODELS.items():
            api_key = os.getenv(config["api_key_env"], "")
            if api_key:
                available.append(model_name)
        return available
