#!/usr/bin/env python3
"""
å®éªŒæ¡†æ¶æµ‹è¯•è„šæœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨metricså’Œablationæ¨¡å—
"""
import sys
import numpy as np
import pandas as pd
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.metrics import (
    brier_score, log_loss_score, ece_score, sharpness,
    paired_t_test, compute_all_metrics
)
from src.ablation import ExperimentConfig, run_ablation, print_ablation_table


def test_metrics():
    """æµ‹è¯•è¯„ä¼°æŒ‡æ ‡"""
    print("=" * 80)
    print("ğŸ§® Metricsæ¨¡å—æµ‹è¯•".center(80))
    print("=" * 80)
    
    # æµ‹è¯•æ•°æ®
    y_true = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])
    p_pred = np.array([0.85, 0.15, 0.90, 0.20, 0.75, 0.25, 0.95, 0.10, 0.80, 0.30])
    
    metrics = compute_all_metrics(y_true, p_pred)
    
    print(f"\nã€äºŒå…ƒåˆ†ç±»æŒ‡æ ‡ã€‘")
    print(f"Brier Score: {metrics['brier']:.4f}")
    print(f"Log Loss: {metrics['log_loss']:.4f}")
    print(f"ECE: {metrics['ece']:.4f}")
    print(f"Sharpness: {metrics['sharpness']:.4f}")
    
    # æµ‹è¯•é…å¯¹tæ£€éªŒ
    scores_before = [0.15, 0.20, 0.18, 0.22, 0.19, 0.17, 0.21]
    scores_after = [0.12, 0.16, 0.15, 0.18, 0.16, 0.14, 0.17]
    t_stat, p_val = paired_t_test(scores_before, scores_after)
    
    print(f"\nã€é…å¯¹tæ£€éªŒã€‘")
    print(f"t-statistic: {t_stat:.4f}")
    print(f"p-value: {p_val:.4f}")
    print(f"æ˜¾è‘—æ€§: {'æ˜¯' if p_val < 0.05 else 'å¦'} (p < 0.05)")
    
    print("\nâœ… Metricsæµ‹è¯•é€šè¿‡ï¼\n")


def test_ablation_example():
    """æ¼”ç¤ºæ¶ˆèå®éªŒ"""
    print("=" * 80)
    print("ğŸ§ª Ablationæ¨¡å—ç¤ºä¾‹".center(80))
    print("=" * 80)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®é›†
    n_samples = 20
    test_data = {
        "market_id": [f"market_{i}" for i in range(n_samples)],
        "resolved_outcome": np.random.randint(0, 2, n_samples),
        "ai_prob": np.random.uniform(30, 70, n_samples),
        "market_prob": np.random.uniform(35, 65, n_samples),
        "timestamp": ["2025-01-01"] * n_samples
    }
    
    df_test = pd.DataFrame(test_data)
    test_csv_path = "/tmp/test_ablation_data.csv"
    df_test.to_csv(test_csv_path, index=False)
    
    print(f"\nğŸ“Š åˆ›å»ºæµ‹è¯•æ•°æ®é›†: {test_csv_path}")
    print(f"   æ•°æ®é‡: {len(df_test)} æ¡")
    print(f"   åˆ—: {list(df_test.columns)}")
    
    # æµ‹è¯•é…ç½®
    config = ExperimentConfig()
    print(f"\nã€å®éªŒé…ç½®ã€‘")
    print(f"consensus_coef: {config.get('FUSION', 'consensus_coef')}")
    print(f"market_bias: {config.get('FUSION', 'market_bias')}")
    print(f"demarket_penalty: {config.get('FUSION', 'demarket_penalty')}")
    print(f"post_calibration: {config.get('CALIBRATION', 'post_calibration')}")
    
    print("\nğŸ’¡ è¿è¡Œå®Œæ•´æ¶ˆèå®éªŒè¯·è°ƒç”¨:")
    print("   results_df = run_ablation(test_csv_path)")
    print("   print_ablation_table(results_df)")
    
    print("\nâœ… Ablationæµ‹è¯•é€šè¿‡ï¼\n")


if __name__ == "__main__":
    test_metrics()
    test_ablation_example()
    
    print("=" * 80)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼".center(80))
    print("=" * 80)



