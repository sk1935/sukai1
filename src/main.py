"""
ä¸»ç¨‹åºï¼ˆMainï¼‰ï¼š
æ ¹æ® OPTIMIZATION_NOTES.md çš„äº”å±‚æ¶æ„è®¾è®¡

ç³»ç»Ÿæ¶æ„ï¼š
1. äº‹ä»¶å±‚ï¼ˆEventManagerï¼‰â†’ è§£æè¾“å…¥ã€è·å–å¸‚åœºæ•°æ®
2. æç¤ºå±‚ï¼ˆPromptBuilderï¼‰â†’ ç”Ÿæˆæ¨¡å‹æç¤ºè¯
3. æ¨ç†å±‚ï¼ˆModelOrchestratorï¼‰â†’ å¹¶å‘è°ƒç”¨å¤šä¸ªAIæ¨¡å‹
4. èåˆå±‚ï¼ˆFusionEngineï¼‰â†’ åŠ æƒèåˆé¢„æµ‹ç»“æœ
5. è¾“å‡ºå±‚ï¼ˆOutputFormatterï¼‰â†’ æ ¼å¼åŒ–ä¸­æ–‡æŠ¥å‘Š

æœ¬æ¨¡å—è´Ÿè´£åè°ƒäº”å±‚æ¶æ„ï¼Œå®ç°å®Œæ•´çš„é¢„æµ‹æµç¨‹ã€‚
"""
import asyncio
import inspect
import logging
import os
from dotenv import load_dotenv
import signal
import sys
from pathlib import Path
from types import SimpleNamespace
from typing import Any, Dict, List, Optional, Tuple

TELEGRAM_AVAILABLE = True
TELEGRAM_BACKEND = "application"

# ã€ä¿®å¤ã€‘åœ¨å¯¼å…¥ telegram.ext ä¹‹å‰ä¿®è¡¥ apscheduler çš„æ—¶åŒºé—®é¢˜
# Python 3.13 çš„ zoneinfo ä¸ apscheduler ä¸å…¼å®¹
try:
    import pytz
    import apscheduler.util
    # åˆ›å»º pytz æ—¶åŒºå¯¹è±¡
    try:
        default_tz = pytz.timezone('Asia/Shanghai')
    except:
        default_tz = pytz.UTC
    
    # ä¿®è¡¥ astimezone å‡½æ•°ï¼Œè®©å®ƒæ¥å— zoneinfo æ—¶åŒºå¹¶è½¬æ¢ä¸º pytz
    original_astimezone = apscheduler.util.astimezone
    def patched_astimezone(tz):
        if tz is None:
            return default_tz
        # å¦‚æœå·²ç»æ˜¯ pytz æ—¶åŒºï¼Œç›´æ¥è¿”å›
        if isinstance(tz, pytz.BaseTzInfo):
            return tz
        # å¦‚æœæ˜¯ zoneinfo æ—¶åŒºï¼Œè½¬æ¢ä¸º pytz
        try:
            from zoneinfo import ZoneInfo
            if isinstance(tz, ZoneInfo):
                # è·å–æ—¶åŒºåç§°
                tz_name = str(tz).split('/')[-1] if '/' in str(tz) else str(tz)
                # å°è¯•è½¬æ¢ä¸º pytz æ—¶åŒº
                try:
                    return pytz.timezone(tz_name)
                except:
                    return default_tz
        except:
            pass
        # å…¶ä»–æƒ…å†µï¼Œå°è¯•åŸå§‹å‡½æ•°
        try:
            return original_astimezone(tz)
        except:
            return default_tz
    
    apscheduler.util.astimezone = patched_astimezone
    print(f"âœ… å·²ä¿®è¡¥ apscheduler æ—¶åŒºå‡½æ•°ï¼Œé»˜è®¤æ—¶åŒº: {default_tz}")
except Exception as e:
    print(f"âš ï¸ ä¿®è¡¥ apscheduler æ—¶åŒºå‡½æ•°å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

try:
    from telegram import Update
    from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
except ImportError:
    try:
        from telegram import Update
        from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext

        TELEGRAM_BACKEND = "legacy"
        ContextTypes = SimpleNamespace(DEFAULT_TYPE=CallbackContext)
        filters = SimpleNamespace(TEXT=Filters.text, COMMAND=Filters.command)

        class LegacyApplication:
            """Shim to provide Application-like interface on top of Updater."""

            def __init__(self, updater):
                self.updater = updater
                self.dispatcher = updater.dispatcher

            @classmethod
            def builder(cls):
                return LegacyApplicationBuilder()

            def add_handler(self, handler, group=0):
                self.dispatcher.add_handler(handler, group=group)

            def add_error_handler(self, handler):
                self.dispatcher.add_error_handler(handler)

            def run_polling(self, **kwargs):
                self.updater.start_polling()
                self.updater.idle()

        class LegacyApplicationBuilder:
            def __init__(self):
                self._token = None

            def token(self, token):
                self._token = token
                return self

            def build(self):
                if not self._token:
                    raise ValueError("TELEGRAM_BOT_TOKEN æœªé…ç½®")
                updater = Updater(token=self._token, use_context=True)
                return LegacyApplication(updater)

        Application = LegacyApplication  # type: ignore
    except ImportError as telegram_import_err:
        TELEGRAM_AVAILABLE = False
        TELEGRAM_IMPORT_ERROR = telegram_import_err
        
        class _DummyUpdate:
            ALL_TYPES = []
        Update = _DummyUpdate  # type: ignore
        
        class _DummyContextTypes:
            DEFAULT_TYPE = object
        ContextTypes = _DummyContextTypes  # type: ignore
        
        class _DummyFilters:
            TEXT = object()
            COMMAND = object()
        filters = _DummyFilters()
        
        class Application:  # type: ignore
            @classmethod
            def builder(cls):
                raise RuntimeError("Telegram dependency unavailable")
        
        class CommandHandler:  # type: ignore
            def __init__(self, *args, **kwargs):
                raise RuntimeError("Telegram dependency unavailable")
        
        class MessageHandler:  # type: ignore
            def __init__(self, *args, **kwargs):
                raise RuntimeError("Telegram dependency unavailable")

# Ensure local src imports always resolve
sys.path.insert(0, str(Path(__file__).parent))
sys.path.insert(0, str(Path(__file__).parent.parent))

from event_manager import EventManager
from prompt_builder import PromptBuilder
from model_orchestrator import ModelOrchestrator
from fusion_engine import FusionEngine
from output_formatter import OutputFormatter
from event_analyzer import EventAnalyzer
from notion_logger import NotionLogger

# OpenRouter é›†æˆ
try:
    from services.llm_clients.openrouter_layer import (
        call_openrouter_model,
        call_multiple_openrouter_models,
        get_available_models as get_openrouter_models,
        is_openrouter_available
    )
    OPENROUTER_INTEGRATION_AVAILABLE = True
except Exception as import_err:
    print(f"âš ï¸ OpenRouter é›†æˆä¸å¯ç”¨: {import_err}")
    OPENROUTER_INTEGRATION_AVAILABLE = False
    
    async def call_openrouter_model(*args, **kwargs):
        raise RuntimeError("OpenRouter integration disabled")
    
    async def call_multiple_openrouter_models(*args, **kwargs):
        return {}
    
    def get_openrouter_models():
        return []
    
    def is_openrouter_available():
        return False

# LMArena åŠ¨æ€æƒé‡æ›´æ–°
try:
    from config.update_lmarena_weights import update_lmarena_weights, should_update
    LMARENA_UPDATE_AVAILABLE = True
except ImportError:
    print("âš ï¸ LMArena æƒé‡æ›´æ–°æ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡è‡ªåŠ¨æ›´æ–°")
    LMARENA_UPDATE_AVAILABLE = False

load_dotenv()


def _configure_logging() -> logging.Logger:
    """Configure application-wide logging once and return module logger."""
    level_name = os.getenv("POLYMARKET_LOG_LEVEL", "INFO").upper()
    level = getattr(logging, level_name, logging.INFO)

    if not logging.getLogger().handlers:
        logging.basicConfig(
            level=level,
            format="%(asctime)s %(levelname)s [%(name)s] %(message)s"
        )
    root_logger = logging.getLogger()
    root_logger.setLevel(level)
    return logging.getLogger("polymarket")


BOT_LOGGER = _configure_logging()


async def maybe_await(result):
    """Await result if it is awaitable, otherwise return it directly."""
    if inspect.isawaitable(result):
        return await result
    return result


def wrap_async_handler(handler):
    """Wrap async handler for legacy (synchronous) telegram backends."""
    if TELEGRAM_AVAILABLE and TELEGRAM_BACKEND == "legacy" and inspect.iscoroutinefunction(handler):
        def _wrapper(update, context):
            asyncio.run(handler(update, context))
        return _wrapper
    return handler


class ForecastingBot:
    """
    Main bot class that orchestrates all components.
    
    é¢„æµ‹æœºå™¨äººä¸»ç±»ï¼š
    - åè°ƒäº”å±‚æ¶æ„çš„å®Œæ•´æµç¨‹
    - å¤„ç† Telegram æ¶ˆæ¯å’Œå‘½ä»¤
    - æ”¯æŒå•é€‰é¡¹å’Œå¤šé€‰é¡¹å¸‚åœºé¢„æµ‹
    - æ‰€æœ‰è¾“å‡ºå‡ä¸ºä¸­æ–‡
    """
    
    def __init__(
        self,
        event_manager: Optional[EventManager] = None,
        prompt_builder: Optional[PromptBuilder] = None,
        model_orchestrator: Optional[ModelOrchestrator] = None,
        fusion_engine: Optional[FusionEngine] = None,
        output_formatter: Optional[OutputFormatter] = None,
        event_analyzer: Optional[EventAnalyzer] = None,
        notion_logger: Optional[NotionLogger] = None,
        logger: Optional[logging.Logger] = None,
    ):
        self.logger = logger or BOT_LOGGER.getChild("bot")
        self.event_manager = event_manager or EventManager()
        self.prompt_builder = prompt_builder or PromptBuilder()
        self.model_orchestrator = model_orchestrator or ModelOrchestrator()
        self.fusion_engine = fusion_engine or FusionEngine()
        self.output_formatter = output_formatter or OutputFormatter()
        self.event_analyzer = event_analyzer or EventAnalyzer()

        # åˆå§‹åŒ– Notion Loggerï¼ˆå¦‚æœé…ç½®äº†ç¯å¢ƒå˜é‡ï¼‰
        if notion_logger is not None:
            self.notion_logger = notion_logger
        else:
            try:
                self.notion_logger = NotionLogger()
                if self.notion_logger and self.notion_logger.enabled:
                    self.logger.info("Notion Logger å·²å¯ç”¨ï¼Œé¢„æµ‹ç»“æœå°†è‡ªåŠ¨ä¿å­˜åˆ° Notion")
                elif self.notion_logger:
                    self.logger.warning("Notion Logger å·²åˆ›å»ºä½†æœªå¯ç”¨ï¼ˆè¯·æ£€æŸ¥é…ç½®ï¼‰")
            except Exception as e:
                self.logger.exception("Notion Logger åˆå§‹åŒ–å¼‚å¸¸: %s", e)
                import traceback
                traceback.print_exc()
                self.notion_logger = None
    
    async def _prepare_prediction_context(
        self,
        update: Update,
        context: ContextTypes.DEFAULT_TYPE
    ) -> Optional[str]:
        """Validate update, show typing indicator, and preload news cache."""
        if not update.message:
            print("âš ï¸ handle_predict: No message in update")
            return None

        message_text = update.message.text or ""
        print(f"\n{'='*60}")
        print(f"ğŸ“¨ æ”¶åˆ°æ¶ˆæ¯: {message_text[:100]}...")
        print(f"{'='*60}")

        try:
            await maybe_await(context.bot.send_chat_action(
                chat_id=update.effective_chat.id,
                action="typing"
            ))
        except Exception as e:
            print(f"âš ï¸ å‘é€typing indicatorå¤±è´¥: {e}")

        try:
            from src.news_cache import fetch_and_cache_news, NEWS_CACHE_ENABLED
            if NEWS_CACHE_ENABLED:
                print("ğŸ“° [NEWS_CACHE] å¼€å§‹é¢„åŠ è½½æ–°é—»ç¼“å­˜...")
                try:
                    await asyncio.wait_for(
                        fetch_and_cache_news(keyword="", force_refresh=False),
                        timeout=15.0
                    )
                    print("âœ… [NEWS_CACHE] æ–°é—»ç¼“å­˜é¢„åŠ è½½å®Œæˆ")
                except asyncio.TimeoutError:
                    print("â±ï¸ [NEWS_CACHE] é¢„åŠ è½½è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œï¼ˆä½¿ç”¨æ—§ç¼“å­˜ï¼‰")
                except Exception as e:
                    print(f"âš ï¸ [NEWS_CACHE] é¢„åŠ è½½å¤±è´¥: {type(e).__name__}: {e}ï¼Œç»§ç»­æ‰§è¡Œ")
            else:
                print("â„¹ï¸ [NEWS_CACHE] åŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡é¢„åŠ è½½")
        except ImportError as e:
            print(f"âš ï¸ [NEWS_CACHE] æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        except Exception as e:
            print(f"âš ï¸ [NEWS_CACHE] é¢„åŠ è½½å¼‚å¸¸: {type(e).__name__}: {e}")

        return message_text

    async def _fetch_event_data(
        self,
        update: Update,
        event_info: Dict[str, str]
    ) -> Dict:
        """Fetch Polymarket data with timeout and mock fallbacks."""
        await maybe_await(update.message.reply_text("ğŸ” æ­£åœ¨è·å–å¸‚åœºæ•°æ®..."))
        print(f"ğŸ” å¼€å§‹è·å–å¸‚åœºæ•°æ®ï¼Œevent_info: {event_info}")
        event_data: Optional[Dict] = None
        try:
            event_data = await asyncio.wait_for(
                self.event_manager.fetch_polymarket_data(event_info),
                timeout=25.0
            )
            if event_data:
                print("âœ… æˆåŠŸè·å–å¸‚åœºæ•°æ®:")
                print(f"  question: {event_data.get('question', 'N/A')[:80]}")
                print(f"  market_prob: {event_data.get('market_prob', 'N/A')}")
                print(f"  is_mock: {event_data.get('is_mock', False)}")
            else:
                print("âš ï¸ event_data ä¸º None")
        except asyncio.TimeoutError:
            print("â±ï¸ è·å–å¸‚åœºæ•°æ®è¶…æ—¶")
            await maybe_await(update.message.reply_text(
                "â±ï¸ è·å–å¸‚åœºæ•°æ®è¶…æ—¶ï¼Œå°†ä½¿ç”¨ AI æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚",
                parse_mode="Markdown"
            ))
            event_data = self.event_manager._create_mock_market_data(event_info.get('query', ''))
            event_data["is_mock"] = True
            return event_data
        except Exception as exc:
            print(f"âš ï¸ è·å–å¸‚åœºæ•°æ®å¼‚å¸¸: {type(exc).__name__}: {exc}")

        if not event_data:
            print("âŒ æœªèƒ½è·å–å¸‚åœºæ•°æ®ï¼Œåˆ›å»ºmockæ•°æ®")
            await maybe_await(update.message.reply_text(
                self.output_formatter.format_error(
                    "è·å–å¸‚åœºæ•°æ®å¤±è´¥ï¼Œå°†ä½¿ç”¨ AI æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚"
                ),
                parse_mode="Markdown"
            ))
            event_data = self.event_manager._create_mock_market_data(event_info.get('query', ''))
            event_data["is_mock"] = True

        return event_data

    async def _analyze_event(
        self,
        event_data: Dict,
        event_info: Dict[str, str]
    ) -> Tuple[Dict, Dict, Optional[str], List[str]]:
        """Run full event analysis, news summary, and model selection."""
        market_slug = event_info.get('slug')
        try:
            full_analysis = await asyncio.wait_for(
                self.event_analyzer.analyze_event_full(
                    event_title=event_data.get("question", ""),
                    event_rules=event_data.get("rules", ""),
                    market_prob=event_data.get("market_prob"),
                    market_slug=market_slug
                ),
                timeout=15.0
            )
            print("âœ… å®Œæ•´äº‹ä»¶åˆ†æå®Œæˆï¼ˆåŒ…å«å¸‚åœºè¶‹åŠ¿ã€èˆ†æƒ…ã€è§„åˆ™æ‘˜è¦ï¼‰")
        except asyncio.TimeoutError:
            print("â±ï¸ [WARNING] äº‹ä»¶åˆ†æè¶…æ—¶ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            full_analysis = {
                "event_category": "general",
                "event_category_display": "é€šç”¨",
                "market_trend": "æ•°æ®ä¸è¶³",
                "sentiment_trend": "unknown",
                "sentiment_score": 0.0,
                "sentiment_sample": 0,
                "sentiment_source": "æœªçŸ¥",
                "rules_summary": event_data.get("rules", "")[:100] if event_data.get("rules") else "æ— è§„åˆ™ä¿¡æ¯"
            }
        except Exception as e:
            print(f"âš ï¸ å®Œæ•´äº‹ä»¶åˆ†æå¤±è´¥: {type(e).__name__}: {e}ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
            full_analysis = {
                "event_category": event_data.get("category", "unknown"),
                "event_category_display": event_data.get("category", "unknown"),
                "market_trend": "åˆ†æå¤±è´¥",
                "sentiment_trend": "unknown",
                "sentiment_score": 0.0,
                "sentiment_sample": 0,
                "sentiment_source": "æœªçŸ¥",
                "rules_summary": event_data.get("rules", "")[:100] if event_data.get("rules") else "æ— è§„åˆ™ä¿¡æ¯"
            }

        print("\nğŸ“Š äº‹ä»¶å…¨é¢åˆ†æ:")
        print(f"  ç±»åˆ«: {full_analysis['event_category']} ({full_analysis.get('event_category_display', 'æœªçŸ¥')})")
        print(f"  å¸‚åœºè¶‹åŠ¿: {full_analysis['market_trend']}")
        sentiment_score = full_analysis.get('sentiment_score') or 0.0
        print(
            f"  èˆ†æƒ…: {full_analysis.get('sentiment_trend', 'unknown')} ({sentiment_score:+.2f}), "
            f"æ ·æœ¬: {full_analysis.get('sentiment_sample', 0)} ({full_analysis.get('sentiment_source', 'æœªçŸ¥')})"
        )
        print(f"  è§„åˆ™æ‘˜è¦: {full_analysis.get('rules_summary', '')[:60]}...")
        world_temp_data = full_analysis.get("world_temp_data")
        if world_temp_data:
            description = world_temp_data.get("description", "æœªçŸ¥")
            positive = world_temp_data.get("positive", 0)
            negative = world_temp_data.get("negative", 0)
            neutral = world_temp_data.get("neutral", 0)
            print(f"  ğŸ§  ä¸–ç•Œæƒ…ç»ª: {description}ï¼ˆæ­£é¢: {positive}, è´Ÿé¢: {negative}, ä¸­æ€§: {neutral}ï¼‰")
        elif full_analysis.get("world_sentiment_summary"):
            print(f"  ğŸ§  ä¸–ç•Œæƒ…ç»ª: {full_analysis['world_sentiment_summary'][:80]}...")

        news_summary = None
        try:
            from src.openrouter_assistant import get_news_summary, OPENROUTER_ASSISTANT_ENABLED
            if OPENROUTER_ASSISTANT_ENABLED:
                news_summary = await asyncio.wait_for(
                    get_news_summary(),
                    timeout=10.0
                )
                if news_summary:
                    print(f"  ğŸ“° æ–°é—»æ‘˜è¦: å·²è·å–ï¼ˆ{len(news_summary)} å­—ç¬¦ï¼‰")
            else:
                print("  â„¹ï¸ [OPENROUTER] åŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡æ–°é—»æ‘˜è¦")
        except asyncio.TimeoutError:
            print("  â±ï¸ [OPENROUTER] è·å–æ–°é—»æ‘˜è¦è¶…æ—¶ï¼ˆ>10sï¼‰ï¼Œè·³è¿‡")
        except ImportError as e:
            print(f"  âš ï¸ [OPENROUTER] æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        except Exception as e:
            print(f"  âš ï¸ [OPENROUTER] è·å–æ–°é—»æ‘˜è¦å¤±è´¥: {type(e).__name__}: {e}")

        event_analysis = self.event_analyzer.analyze_event(
            event_data.get("question", ""),
            event_data.get("rules", ""),
            available_models=None,
            orchestrator=self.model_orchestrator
        )
        print(f"\nğŸ“Š Event Category: {event_analysis['category']}")
        print(f"ğŸ“ Dimensions: {len(event_analysis['dimensions'])}")
        model_names = [
            model for model in event_analysis["model_assignments"].keys()
            if model in self.model_orchestrator.get_available_models()
        ]
        event_data["full_analysis"] = full_analysis
        event_data["world_temp"] = full_analysis.get("world_temp")
        event_data["world_temp_data"] = full_analysis.get("world_temp_data")
        event_data["world_sentiment_summary"] = full_analysis.get("world_sentiment_summary")
        event_data["news_summary"] = news_summary
        return event_analysis, full_analysis, news_summary, model_names

    def _build_binary_prompts(
        self,
        event_data: Dict,
        model_assignments: Dict,
        model_names: List[str]
    ) -> Dict[str, str]:
        """Construct per-model prompts for binary predictions."""
        prompts: Dict[str, str] = {}
        for model_name in model_names:
            assignment = model_assignments.get(model_name)
            prompt = self.prompt_builder.build_prompt(
                event_data,
                model_name,
                model_assignment=assignment
            )
            prompts[model_name] = prompt
            if assignment:
                print(f"  âœ… {model_name}: {assignment['dimension_name']}")
        return prompts

    async def _call_binary_models(
        self,
        update: Update,
        prompts: Dict[str, str]
    ) -> Optional[Dict[str, Optional[Dict[str, Any]]]]:
        """Call orchestrator models (plus OpenRouter) with shared timeout and fallbacks."""
        await maybe_await(update.message.reply_text("ğŸ¤– æ­£åœ¨æŸ¥è¯¢ AI æ¨¡å‹..."))
        print(f"\nğŸ“ Calling {len(prompts)} models: {list(prompts.keys())}")

        try:
            timeout = self.model_orchestrator.MAX_TOTAL_WAIT_TIME
            model_results = await asyncio.wait_for(
                self.model_orchestrator.call_all_models(prompts),
                timeout=float(timeout)
            )

            success_count = sum(1 for r in model_results.values() if r is not None)

            if OPENROUTER_INTEGRATION_AVAILABLE and is_openrouter_available():
                print(f"\nğŸ†“ [OpenRouter] è°ƒç”¨å…è´¹æ¨¡å‹ä½œä¸ºè¾…åŠ©å±‚...")
                openrouter_models = get_openrouter_models()
                selected_models = openrouter_models[:2] if len(openrouter_models) >= 2 else openrouter_models

                if selected_models:
                    common_prompt = list(prompts.values())[0] if prompts else ""

                    try:
                        openrouter_results = await asyncio.wait_for(
                            call_multiple_openrouter_models(selected_models, common_prompt),
                            timeout=30.0
                        )

                        openrouter_success = 0
                        for model_name, result in openrouter_results.items():
                            if result:
                                display_name = model_name.split('/')[-1]
                                model_results[f"openrouter_{display_name}"] = result
                                openrouter_success += 1

                        if openrouter_success > 0:
                            print(f"âœ… [OpenRouter] {openrouter_success}/{len(selected_models)} ä¸ªæ¨¡å‹è°ƒç”¨æˆåŠŸ")
                            success_count += openrouter_success
                        else:
                            print("âš ï¸ [OpenRouter] æ‰€æœ‰æ¨¡å‹è°ƒç”¨å¤±è´¥")

                    except asyncio.TimeoutError:
                        print("â±ï¸ [OpenRouter] è°ƒç”¨è¶…æ—¶ï¼Œè·³è¿‡")
                    except Exception as e:
                        print(f"âš ï¸ [OpenRouter] è°ƒç”¨å¼‚å¸¸: {type(e).__name__}: {e}")
            else:
                print("â„¹ï¸ [OpenRouter] API å¯†é’¥æœªé…ç½®ï¼Œè·³è¿‡å…è´¹æ¨¡å‹è°ƒç”¨")

            if success_count == 0:
                print("âš ï¸ [WARNING] æ‰€æœ‰æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¸‚åœºä»·æ ¼ä½œä¸ºfallback")
                await maybe_await(update.message.reply_text(
                    "âš ï¸ AIæ¨¡å‹æš‚æ—¶æ— å“åº”ï¼Œå°†ä½¿ç”¨å¸‚åœºä»·æ ¼è¿›è¡Œé¢„æµ‹ã€‚",
                    parse_mode="Markdown"
                ))
            elif success_count < len(prompts):
                print(f"âš ï¸ [WARNING] éƒ¨åˆ†æ¨¡å—å“åº”æ…¢ï¼š{success_count}/{len(prompts)} ä¸ªæ¨¡å‹æˆåŠŸ")

            return model_results

        except asyncio.TimeoutError:
            timeout = self.model_orchestrator.MAX_TOTAL_WAIT_TIME
            print(f"â±ï¸ [ERROR] æ¨¡å‹æŸ¥è¯¢æ€»è¶…æ—¶ï¼ˆ>{timeout}sï¼‰")
            import traceback
            print("[DEBUG] Timeout exception traceback:")
            traceback.print_exc()

            try:
                model_results = {
                    name: {
                        "probability": 50.0,
                        "confidence": "low",
                        "reasoning": "Overall timeout"
                    }
                    for name in prompts.keys()
                }
                await maybe_await(update.message.reply_text(
                    "âš ï¸ éƒ¨åˆ†æ¨¡å—å“åº”å»¶è¿Ÿï¼Œç»“æœå¯èƒ½ä¸å®Œå…¨å‡†ç¡®ã€‚",
                    parse_mode="Markdown"
                ))
                return model_results
            except Exception as e:
                print(f"âŒ [ERROR] å¤„ç†è¶…æ—¶å¼‚å¸¸å¤±è´¥: {type(e).__name__}: {e}")
                import traceback
                traceback.print_exc()
                await maybe_await(update.message.reply_text(
                    "â±ï¸ æ¨¡å‹æŸ¥è¯¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                    parse_mode="Markdown"
                ))
                return None

    async def _finalize_binary_prediction(
        self,
        update: Update,
        event_data: Dict,
        model_results: Dict[str, Optional[Dict[str, Any]]],
        model_names: List[str],
        full_analysis: Dict
    ) -> None:
        """Fuse model outputs, compute trade signal, format output, and log to Notion."""
        print(f"\nğŸ“Š Model Results:")
        for model_name, result in model_results.items():
            if result:
                print(f"  âœ… {model_name}: {result.get('probability')}% ({result.get('confidence')})")
            else:
                print(f"  âŒ {model_name}: No response")

        model_weights = {
            model_name: self.model_orchestrator.get_model_weight(model_name)
            for model_name in model_names
        }

        if OPENROUTER_INTEGRATION_AVAILABLE and is_openrouter_available():
            openrouter_models = get_openrouter_models()
            for model_name in openrouter_models[:2]:
                display_name = model_name.split('/')[-1]
                openrouter_key = f"openrouter_{display_name}"
                if openrouter_key in model_results and model_results[openrouter_key]:
                    model_weights[openrouter_key] = 0.5

        fusion_result = self.fusion_engine.fuse_predictions(
            model_results=model_results,
            model_weights=model_weights,
            market_prob=event_data["market_prob"],
            orchestrator=self.model_orchestrator
        )

        trade_signal_data = None
        if fusion_result:
            ai_prob_trade = fusion_result.get("model_only_prob")
            if ai_prob_trade is None:
                ai_prob_trade = fusion_result.get("final_prob")
            market_prob_trade = event_data.get("market_prob")
            market_prob_trade = (
                market_prob_trade if market_prob_trade is not None else fusion_result.get("final_prob")
            )
            days_to_resolution = event_data.get("days_left") or 30
            uncertainty_ratio = (fusion_result.get("uncertainty") or 0.0) / 100.0
            trade_signal_data = self.fusion_engine.evaluate_trade_signal(
                ai_prob_trade,
                market_prob_trade,
                days_to_resolution,
                uncertainty_ratio
            )
            print(
                f"[TRADE_SIGNAL] computed event={event_data.get('question', 'N/A')} "
                f"signal={trade_signal_data.get('signal')} ev={trade_signal_data.get('ev')}"
            )
            fusion_result["trade_signal"] = trade_signal_data
            fusion_result["ev"] = trade_signal_data.get("ev")
            fusion_result["annualized_ev"] = trade_signal_data.get("annualized_ev")
            fusion_result["risk_factor"] = trade_signal_data.get("risk_factor")
            fusion_result["signal"] = trade_signal_data.get("signal")
            fusion_result["signal_reason"] = trade_signal_data.get("signal_reason")

        output = self.output_formatter.format_prediction(
            event_data=event_data,
            fusion_result=fusion_result,
            trade_signal=trade_signal_data
        )

        await maybe_await(update.message.reply_text(
            output,
            parse_mode="Markdown"
        ))

        if self.notion_logger:
            if not self.notion_logger.enabled:
                print("âš ï¸ Notion Logger æœªå¯ç”¨ï¼Œè·³è¿‡è®°å½•ï¼ˆå•é€‰é¡¹äº‹ä»¶ï¼‰")
        if self.notion_logger and self.notion_logger.enabled:
            try:
                event_data_for_notion = event_data.copy()
                if full_analysis:
                    event_data_for_notion["category"] = full_analysis.get(
                        "event_category_display",
                        full_analysis.get("event_category", "-")
                    )
                if "outcomes" not in event_data_for_notion:
                    event_data_for_notion["outcomes"] = ["Yes"]

                fusion_result_for_notion = fusion_result.copy()
                if "models" not in fusion_result_for_notion:
                    model_versions = fusion_result.get("model_versions", {})
                    if model_versions:
                        fusion_result_for_notion["models"] = [
                            info.get("display_name", model_id)
                            for model_id, info in model_versions.items()
                        ]
                    else:
                        fusion_result_for_notion["models"] = model_names
                if "run_id" not in fusion_result_for_notion:
                    import uuid
                    fusion_result_for_notion["run_id"] = str(uuid.uuid4())

                self.notion_logger.log_prediction(
                    event_data=event_data_for_notion,
                    fusion_result=fusion_result_for_notion,
                    full_analysis=full_analysis,
                    outcomes=None,
                    normalization_info=None,
                    trade_signal=None
                )
            except Exception as e:
                print(f"âš ï¸ Notion Logger è®°å½•å¤±è´¥: {e}")

    def _gather_multi_option_prompts(
        self,
        event_data: Dict,
        model_assignments: Dict,
        model_names: List[str],
        outcome: Dict
    ) -> Dict[str, str]:
        """Build prompts for a single multi-option outcome."""
        outcome_name = outcome.get("name", "æœªçŸ¥é€‰é¡¹")
        print(f"[MULTI_FLOW] Building prompts for outcome: {outcome_name}")
        prompts: Dict[str, str] = {}
        for model_name in model_names:
            assignment = model_assignments.get(model_name)
            option_event_data = event_data.copy()
            option_event_data["question"] = f"{event_data.get('question', '')} - {outcome_name}"
            option_event_data["market_prob"] = outcome.get("market_prob")
            prompt = self.prompt_builder.build_prompt(
                option_event_data,
                model_name,
                model_assignment=assignment
            )
            prompts[model_name] = prompt
            if assignment:
                print(f"   - {model_name}: {assignment['dimension_name']}")
        if not prompts:
            print(f"[MULTI_FLOW] No prompts constructed for {outcome_name}")
        return prompts

    async def _run_multi_option_models(
        self,
        outcome_name: str,
        prompts: Dict[str, str]
    ) -> Dict[str, Optional[Dict[str, Any]]]:
        """Call models (with retries + OpenRouter) for a single outcome."""
        if not prompts:
            return {}

        print(f"[MULTI_FLOW] Running models for outcome: {outcome_name} ({len(prompts)} prompts)")
        max_retries = 2
        timeout = min(
            self.model_orchestrator.MAX_TOTAL_WAIT_TIME,
            30.0
        )
        model_results: Dict[str, Optional[Dict[str, Any]]] = {}

        for retry in range(max_retries):
            try:
                print(f"ğŸ“¤ è°ƒç”¨ {len(prompts)} ä¸ªæ¨¡å‹ï¼ˆå°è¯• {retry + 1}/{max_retries}ï¼‰")
                model_results = await asyncio.wait_for(
                    self.model_orchestrator.call_all_models(prompts),
                    timeout=timeout
                )
                success_count = sum(1 for r in model_results.values() if r)
                if success_count > 0:
                    break
                if retry < max_retries - 1 and success_count == 0:
                    print(f"  âš ï¸ {outcome_name} é¦–æ¬¡è°ƒç”¨æ— ç»“æœï¼Œç­‰å¾… 1 ç§’åé‡è¯•...")
                    await asyncio.sleep(1)
                    continue
            except asyncio.TimeoutError:
                if retry < max_retries - 1:
                    print(f"  â±ï¸ {outcome_name} è¶…æ—¶ï¼ˆ>{timeout}sï¼‰ï¼Œé‡è¯• {retry + 1}/{max_retries}...")
                    await asyncio.sleep(1)
                    continue
                print(f"  â±ï¸ [ERROR] {outcome_name} é‡è¯•åä»è¶…æ—¶ï¼ˆ>{timeout}sï¼‰ï¼Œä½¿ç”¨å¸‚åœºä»·æ ¼")
                model_results = {}
                break
            except Exception as e:
                if retry < max_retries - 1:
                    print(f"  âš ï¸ {outcome_name} è°ƒç”¨å¼‚å¸¸ ({type(e).__name__})ï¼Œé‡è¯• {retry + 1}/{max_retries}...")
                    await asyncio.sleep(1)
                    continue
                print(f"  âŒ [ERROR] {outcome_name} é‡è¯•åä»å¼‚å¸¸: {type(e).__name__}: {e}")
                model_results = {}
                break

        if OPENROUTER_INTEGRATION_AVAILABLE and is_openrouter_available():
            openrouter_models = get_openrouter_models()
            if openrouter_models:
                selected_model = openrouter_models[0]
                option_prompt = list(prompts.values())[0] if prompts else ""
                try:
                    openrouter_result = await asyncio.wait_for(
                        call_openrouter_model(selected_model, option_prompt),
                        timeout=25.0
                    )
                    if openrouter_result:
                        display_name = selected_model.split('/')[-1]
                        model_results[f"openrouter_{display_name}"] = openrouter_result
                        print(f"âœ… [OpenRouter] {display_name} è°ƒç”¨æˆåŠŸï¼ˆ{outcome_name}ï¼‰")
                except Exception as e:
                    print(f"âš ï¸ [OpenRouter] {outcome_name} è°ƒç”¨å¼‚å¸¸: {type(e).__name__}")

        success_count = sum(1 for r in model_results.values() if r)
        expected_count = len(prompts) + (
            1 if OPENROUTER_INTEGRATION_AVAILABLE and is_openrouter_available() and get_openrouter_models() else 0
        )
        print(f"ğŸ“¥ {outcome_name} æ”¶åˆ° {success_count}/{expected_count} ä¸ªæ¨¡å‹å“åº”")
        if success_count == 0:
            print(f"  âš ï¸ [WARNING] {outcome_name} æ‰€æœ‰æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œå°†ä½¿ç”¨å¸‚åœºä»·æ ¼")
            print(f"  [DEBUG] æ¨¡å‹ç»“æœè¯¦æƒ…: {model_results}")
            print(f"  [DEBUG] æ˜¯å¦æœ‰ç»“æœ: {bool(model_results)}, ç»“æœæ•°é‡: {len(model_results)}")
        else:
            print(f"  âœ… {outcome_name} æˆåŠŸè·å¾— {success_count} ä¸ªæ¨¡å‹å“åº”")

        return model_results

    def _fuse_multi_option_outcome(
        self,
        outcome: Dict,
        outcome_results: Dict[str, Optional[Dict[str, Any]]],
        model_weights: Dict[str, float],
        current_reasoning: Optional[str]
    ) -> Tuple[Dict[str, Any], Optional[str]]:
        """Fuse predictions (or fallback) for a single outcome."""
        outcome_name = outcome.get("name", "æœªçŸ¥é€‰é¡¹")
        print(f"[MULTI_FLOW] Fusing outcome: {outcome_name}")
        valid_count = sum(1 for r in outcome_results.values() if r is not None)

        if valid_count > 0:
            fusion_result = self.fusion_engine.fuse_predictions(
                model_results=outcome_results,
                model_weights=model_weights,
                market_prob=outcome["market_prob"],
                orchestrator=self.model_orchestrator
            )
            if not current_reasoning and fusion_result.get("deepseek_reasoning"):
                current_reasoning = fusion_result.get("deepseek_reasoning")

            final_prob = fusion_result.get("final_prob") or 0.0
            if final_prob is None:
                print(f"âš ï¸ final_prob is None for {outcome_name}, using default 0.0")
                final_prob = 0.0

            model_only_prob_value = fusion_result.get("model_only_prob")
            if model_only_prob_value is None:
                model_only_prob_display = "N/A"
            else:
                model_only_prob_value = model_only_prob_value or 0.0
                if model_only_prob_value is None:
                    print("âš™ï¸ [SAFE] ä¿®å¤ç©ºå€¼ä¿æŠ¤: model_only_prob_display")
                    model_only_prob_value = 0.0
                model_only_prob_display = f"{(model_only_prob_value or 0.0):.1f}%"

            print(f"  âœ… èåˆå®Œæˆ: {outcome_name} = {(final_prob or 0.0):.1f}% (AI: {model_only_prob_display})")

            fused_outcome = {
                "name": outcome_name,
                "prediction": fusion_result["final_prob"],
                "market_prob": outcome["market_prob"],
                "uncertainty": fusion_result["uncertainty"],
                "summary": fusion_result["summary"],
                "model_only_prob": fusion_result.get("model_only_prob"),
                "model_versions": fusion_result.get("model_versions", {}),
                "weight_source": fusion_result.get("weight_source", {}),
                "deepseek_reasoning": fusion_result.get("deepseek_reasoning")
            }
            return fused_outcome, current_reasoning

        if not outcome_results:
            reason = "æ— æ¨¡å‹ç»“æœ"
        elif valid_count == 0:
            reason = "æ‰€æœ‰æ¨¡å‹è°ƒç”¨å¤±è´¥/è¶…æ—¶"
        else:
            reason = "æ— æœ‰æ•ˆæ¨¡å‹ç»“æœ"

        market_prob = outcome.get("market_prob") or 0.0
        if market_prob is None:
            print(f"âš ï¸ market_prob is None for {outcome_name}, using default 0.0")
            market_prob = 0.0
        print(f"  âš ï¸ æ— AIé¢„æµ‹: {outcome_name}ï¼ˆ{reason}ï¼Œæœ‰æ•ˆç»“æœæ•°: {valid_count}ï¼‰ï¼Œä½¿ç”¨å¸‚åœºä»·æ ¼ {(market_prob or 0.0):.1f}%")

        fused_outcome = {
            "name": outcome_name,
            "prediction": outcome["market_prob"],
            "market_prob": outcome["market_prob"],
            "uncertainty": 10.0,
            "summary": f"âš ï¸ {reason}ï¼Œæš‚æ—  AI æ¨¡å‹é¢„æµ‹ï¼Œæ˜¾ç¤ºå¸‚åœºä»·æ ¼",
            "model_only_prob": None
        }
        return fused_outcome, current_reasoning

    async def _finalize_multi_option_response(
        self,
        update: Update,
        event_data: Dict,
        fused_outcomes: List[Dict[str, Any]],
        raw_outcomes: List[Dict[str, Any]],
        full_analysis: Dict,
        deepseek_reasoning: Optional[str],
        model_names: List[str]
    ) -> None:
        """Normalize, format, and log multi-option predictions."""
        print("[MULTI_FLOW] Finalizing multi-option response")
        if not fused_outcomes and raw_outcomes:
            print(f"âš ï¸ fused_outcomes ä¸ºç©ºï¼Œä»åŸå§‹ outcomes åˆ›å»º fallback æ•°æ®...")
            fused_outcomes.extend([{
                "name": outcome["name"],
                "prediction": outcome["market_prob"],
                "market_prob": outcome["market_prob"],
                "uncertainty": 10.0,
                "summary": "æš‚æ—  AI æ¨¡å‹é¢„æµ‹ï¼Œæ˜¾ç¤ºå¸‚åœºä»·æ ¼ã€‚",
                "model_only_prob": None
            } for outcome in raw_outcomes])
            print(f"âœ… åˆ›å»ºäº† {len(fused_outcomes)} ä¸ª fallback outcomes")
        elif not fused_outcomes:
            print("âŒ ä¸¥é‡é”™è¯¯ï¼šæ—¢æ²¡æœ‰ fused_outcomes ä¹Ÿæ²¡æœ‰ outcomesï¼")

        print(f"ğŸ“Š å½’ä¸€åŒ–å‰ fused_outcomes æ•°é‡: {len(fused_outcomes)}")
        event_title = event_data.get("question", "")
        normalization_result = self.fusion_engine.normalize_all_predictions(
            fused_outcomes,
            event_title=event_title,
            event_rules=event_data.get("rules", ""),
            now_probabilities=[
                outcome.get("market_prob")
                for outcome in fused_outcomes
                if outcome.get("market_prob") is not None
            ]
        )

        fused_outcomes = normalization_result["normalized_outcomes"]

        print(f"ğŸ“Š å½’ä¸€åŒ–ç»“æœ:")
        total_before = normalization_result.get('total_before')
        total_after = normalization_result.get('total_after')
        error = normalization_result.get('error', 0)
        skipped_count = normalization_result.get('skipped_count', 0)

        try:
            if total_before is not None:
                total_before = total_before or 0.0
                if total_before is None:
                    print("âš™ï¸ [SAFE] ä¿®å¤ç©ºå€¼ä¿æŠ¤: total_before")
                    total_before = 0.0
                print(f"   å½’ä¸€åŒ–å‰æ€»å’Œ: {float(total_before or 0.0):.2f}%")
            else:
                print(f"   å½’ä¸€åŒ–å‰æ€»å’Œ: N/A")

            if total_after is not None:
                total_after = total_after or 0.0
                if total_after is None:
                    print("âš™ï¸ [SAFE] ä¿®å¤ç©ºå€¼ä¿æŠ¤: total_after")
                    total_after = 0.0
                print(f"   å½’ä¸€åŒ–åæ€»å’Œ: {float(total_after or 0.0):.2f}%")
            else:
                print(f"   å½’ä¸€åŒ–åæ€»å’Œ: N/Aï¼ˆæ¡ä»¶äº‹ä»¶æœªå½’ä¸€åŒ–ï¼‰")

            if error is not None:
                error = error or 0.0
                if error is None:
                    print("âš™ï¸ [SAFE] ä¿®å¤ç©ºå€¼ä¿æŠ¤: error")
                    error = 0.0
                print(f"   è¯¯å·®: {float(error or 0.0):.4f}%")
            else:
                print(f"   è¯¯å·®: N/A")

            print(f"   è·³è¿‡é€‰é¡¹: {skipped_count} ä¸ª")
        except (TypeError, ValueError):
            print("  âš ï¸ å½’ä¸€åŒ–ç»“æœæ•°æ®æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡æ ¼å¼åŒ–")
            print(f"   è·³è¿‡é€‰é¡¹: {skipped_count} ä¸ª")

        if normalization_result.get('total_after', 0) == 0 and normalization_result.get('total_before', 0) > 0:
            print(f"âš ï¸ [WARNING] å½’ä¸€åŒ–å¼‚å¸¸ï¼štotal_before={normalization_result['total_before']}ï¼Œä½† total_after=0")
        print(f"[DEBUG] normalization_result keys: {list(normalization_result.keys())}")
        print(f"[DEBUG] normalization_result['total_after'] = {normalization_result.get('total_after')}")

        print(f"ğŸ“Š å½’ä¸€åŒ–å fused_outcomes æ•°é‡: {len(fused_outcomes)}")

        trade_signal_info = None
        if fused_outcomes:
            def _diff_metric(outcome):
                ai_val = outcome.get("model_only_prob")
                if ai_val is None:
                    ai_val = outcome.get("prediction", 0.0)
                return abs((ai_val or 0.0) - (outcome.get("market_prob") or 0.0))

            top_outcome = max(fused_outcomes, key=_diff_metric)
            ai_prob_trade = top_outcome.get("model_only_prob")
            if ai_prob_trade is None:
                ai_prob_trade = top_outcome.get("prediction")
            market_prob_trade = top_outcome.get("market_prob")
            days_to_resolution = event_data.get("days_left") or 30
            uncertainty_ratio = (top_outcome.get("uncertainty") or 0.0) / 100.0
            trade_data = self.fusion_engine.evaluate_trade_signal(
                ai_prob_trade,
                market_prob_trade,
                days_to_resolution,
                uncertainty_ratio
            )
            print(
                f"[TRADE_SIGNAL] computed option={top_outcome.get('name', 'N/A')} "
                f"signal={trade_data.get('signal')} ev={trade_data.get('ev')}"
            )
            trade_signal_info = {
                **trade_data,
                "option": top_outcome.get("name", "N/A"),
                "option_id": top_outcome.get("id"),
                "option_slug": top_outcome.get("slug")
            }

        multi_option_fusion_result: Dict[str, Any] = {"deepseek_reasoning": deepseek_reasoning}
        if trade_signal_info:
            multi_option_fusion_result["trade_signal"] = trade_signal_info
            multi_option_fusion_result["ev"] = trade_signal_info.get("ev")
            multi_option_fusion_result["annualized_ev"] = trade_signal_info.get("annualized_ev")
            multi_option_fusion_result["risk_factor"] = trade_signal_info.get("risk_factor")
            multi_option_fusion_result["signal"] = trade_signal_info.get("signal")
            multi_option_fusion_result["signal_reason"] = trade_signal_info.get("signal_reason")

        output = self.output_formatter.format_multi_option_prediction(
            event_data=event_data,
            outcomes=fused_outcomes,
            normalization_info=normalization_result,
            fusion_result=multi_option_fusion_result,
            trade_signal=trade_signal_info
        )

        print(f"ğŸ“¤ å‡†å¤‡å‘é€è¾“å‡ºï¼Œé•¿åº¦: {len(output)} å­—ç¬¦")
        await maybe_await(update.message.reply_text(
            output,
            parse_mode="Markdown"
        ))

        if self.notion_logger:
            if not self.notion_logger.enabled:
                print("âš ï¸ Notion Logger æœªå¯ç”¨ï¼Œè·³è¿‡è®°å½•ï¼ˆå¤šé€‰é¡¹äº‹ä»¶ï¼‰")
        if self.notion_logger and self.notion_logger.enabled:
            try:
                aggregated_fusion_result = {
                    "summary": fused_outcomes[0].get("summary", "æš‚æ— æ‘˜è¦") if fused_outcomes else "æš‚æ— æ‘˜è¦",
                    "deepseek_reasoning": deepseek_reasoning,
                    "model_versions": None,
                    "weight_source": None
                }

                if fused_outcomes and len(fused_outcomes) > 0:
                    first_outcome = fused_outcomes[0]
                    if "model_versions" in first_outcome:
                        aggregated_fusion_result["model_versions"] = first_outcome["model_versions"]
                    if "weight_source" in first_outcome:
                        aggregated_fusion_result["weight_source"] = first_outcome["weight_source"]

                if "models" not in aggregated_fusion_result:
                    model_versions = aggregated_fusion_result.get("model_versions", {})
                    if model_versions:
                        aggregated_fusion_result["models"] = [
                            info.get("display_name", model_id)
                            for model_id, info in model_versions.items()
                        ]
                    else:
                        aggregated_fusion_result["models"] = model_names

                if "run_id" not in aggregated_fusion_result:
                    import uuid
                    aggregated_fusion_result["run_id"] = str(uuid.uuid4())

                event_data_for_notion = event_data.copy()
                if full_analysis:
                    event_data_for_notion["category"] = full_analysis.get(
                        "event_category_display",
                        full_analysis.get("event_category", "-")
                    )
                if "outcomes" not in event_data_for_notion and fused_outcomes:
                    event_data_for_notion["outcomes"] = [outcome.get("name", "-") for outcome in fused_outcomes[:1]]

                self.notion_logger.log_prediction(
                    event_data=event_data_for_notion,
                    fusion_result=aggregated_fusion_result,
                    full_analysis=full_analysis,
                    outcomes=fused_outcomes,
                    normalization_info=normalization_result,
                    trade_signal=None
                )
            except Exception as e:
                print(f"âš ï¸ Notion Logger è®°å½•å¤±è´¥: {e}")

    async def handle_predict(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /predict command."""
        message_text = await self._prepare_prediction_context(update, context)
        if message_text is None:
            return

        self.logger.info("æ”¶åˆ° /predict è¯·æ±‚: %s", message_text.strip()[:120])

        try:
            # Parse event
            event_info = self.event_manager.parse_event_from_message(message_text)
            
            if not event_info.get('query'):
                await maybe_await(update.message.reply_text(
                    "è¯·æä¾›è¦é¢„æµ‹çš„äº‹ä»¶ã€‚\n"
                    "ç”¨æ³•: /predict <äº‹ä»¶æè¿°>\n"
                    "æˆ–: /predict <Polymarketé“¾æ¥>"
                ))
                return
            
            event_data = await self._fetch_event_data(update, event_info)

            low_probability_info = self.event_manager.filter_low_probability_event(event_data)
            if low_probability_info:
                notice_text = self.output_formatter.format_low_probability_notice(
                    event_data,
                    threshold=low_probability_info["threshold"],
                    max_probability=low_probability_info["max_probability"]
                )
                self.logger.warning(
                    "äº‹ä»¶è¢«è¿‡æ»¤ï¼ŒåŸå› ï¼šä½æ¦‚ç‡ (question=%s, max_prob=%.2f, threshold=%.2f)",
                    event_data.get("question", "æœªçŸ¥äº‹ä»¶"),
                    low_probability_info["max_probability"],
                    low_probability_info["threshold"]
                )
                await maybe_await(update.message.reply_text(
                    notice_text,
                    parse_mode="Markdown"
                ))
                return

            (
                event_analysis,
                full_analysis,
                news_summary,
                model_names
            ) = await self._analyze_event(event_data, event_info)
            
            # Get model assignments from analysis
            # å…¨é¢åˆ†æäº‹ä»¶ï¼ˆåŒ…å«å¸‚åœºè¶‹åŠ¿ã€äº‹ä»¶ç±»åˆ«ã€èˆ†æƒ…ä¿¡å·ã€è§„åˆ™æ‘˜è¦ï¼‰
            # æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œé¿å…åˆ†ææ­¥éª¤é˜»å¡ä¸»æµç¨‹
            market_slug = event_info.get('slug')
            try:
                full_analysis = await asyncio.wait_for(
                    self.event_analyzer.analyze_event_full(
                        event_title=event_data.get("question", ""),
                        event_rules=event_data.get("rules", ""),
                        market_prob=event_data.get("market_prob"),
                        market_slug=market_slug
                    ),
                    timeout=15.0  # åˆ†ææ­¥éª¤æœ€å¤šç­‰å¾…15ç§’
                )
            except asyncio.TimeoutError:
                print(f"â±ï¸ [WARNING] äº‹ä»¶åˆ†æè¶…æ—¶ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                # ä½¿ç”¨é»˜è®¤åˆ†æç»“æœï¼Œä¸é˜»å¡ä¸»æµç¨‹
                full_analysis = {
                    "event_category": "general",
                    "event_category_display": "é€šç”¨",
                    "market_trend": "æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—",
                    "sentiment_trend": "unknown",
                    "sentiment_score": 0.0,
                    "sentiment_sample": 0,
                    "sentiment_source": "æœªçŸ¥",
                    "rules_summary": event_data.get("rules", "")[:100] if event_data.get("rules") else "æ— è§„åˆ™ä¿¡æ¯"
                }
            
            # æ‰“å°åˆ†æç»“æœ
            print(f"\nğŸ“Š äº‹ä»¶å…¨é¢åˆ†æ:")
            print(f"  ç±»åˆ«: {full_analysis['event_category']} ({full_analysis.get('event_category_display', 'æœªçŸ¥')})")
            print(f"  å¸‚åœºè¶‹åŠ¿: {full_analysis['market_trend']}")
            # ã€é˜²å¾¡ã€‘ç¡®ä¿ sentiment_score ä¸ä¸º None
            sentiment_score = full_analysis.get('sentiment_score') or 0.0
            if sentiment_score is None:
                print("âš ï¸ sentiment_score is None, using default 0.0")
                sentiment_score = 0.0
            print(f"  èˆ†æƒ…: {full_analysis['sentiment_trend']} ({(sentiment_score or 0.0):+.2f}), "
                  f"æ ·æœ¬: {full_analysis['sentiment_sample']} ({full_analysis['sentiment_source']})")
            print(f"  è§„åˆ™æ‘˜è¦: {full_analysis['rules_summary'][:60]}...")
            
            # æ‰“å°ä¸–ç•Œæ¸©åº¦ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰- è½»é‡æè¿°æ¨¡å¼
            world_temp_data = full_analysis.get("world_temp_data")
            if world_temp_data:
                description = world_temp_data.get("description", "æœªçŸ¥")
                positive = world_temp_data.get("positive", 0)
                negative = world_temp_data.get("negative", 0)
                neutral = world_temp_data.get("neutral", 0)
                print(f"  ğŸ§  ä¸–ç•Œæƒ…ç»ª: {description}ï¼ˆæ­£é¢: {positive}, è´Ÿé¢: {negative}, ä¸­æ€§: {neutral}ï¼‰")
            elif full_analysis.get("world_sentiment_summary"):
                print(f"  ğŸ§  ä¸–ç•Œæƒ…ç»ª: {full_analysis['world_sentiment_summary'][:80]}...")
            
            # å¼‚æ­¥è·å–æ–°é—»æ‘˜è¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            # ã€ç¨³å®šæ€§ä¿æŠ¤ã€‘æ·»åŠ è¶…æ—¶å’Œå¼‚å¸¸å¤„ç†
            news_summary = None
            try:
                from src.openrouter_assistant import get_news_summary, OPENROUTER_ASSISTANT_ENABLED
                if OPENROUTER_ASSISTANT_ENABLED:
                    news_summary = await asyncio.wait_for(
                        get_news_summary(),
                        timeout=10.0  # æœ€å¤šç­‰å¾…10ç§’
                    )
                    if news_summary:
                        print(f"  ğŸ“° æ–°é—»æ‘˜è¦: å·²è·å–ï¼ˆ{len(news_summary)} å­—ç¬¦ï¼‰")
                else:
                    print("  â„¹ï¸ [OPENROUTER] åŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡æ–°é—»æ‘˜è¦")
            except asyncio.TimeoutError:
                print(f"  â±ï¸ [OPENROUTER] è·å–æ–°é—»æ‘˜è¦è¶…æ—¶ï¼ˆ>10sï¼‰ï¼Œè·³è¿‡")
                news_summary = None
            except ImportError as e:
                print(f"  âš ï¸ [OPENROUTER] æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
                news_summary = None
            except Exception as e:
                print(f"  âš ï¸ [OPENROUTER] è·å–æ–°é—»æ‘˜è¦å¤±è´¥: {type(e).__name__}: {e}")
                news_summary = None
            
            # ä¿ç•™åŸæœ‰çš„äº‹ä»¶åˆ†æï¼ˆç”¨äºæ¨¡å‹åˆ†é…ï¼‰
            # Pass orchestrator to auto-fetch enabled models
            event_analysis = self.event_analyzer.analyze_event(
                event_data.get("question", ""),
                event_data.get("rules", ""),
                available_models=None,  # è®© analyze_event è‡ªåŠ¨ä» orchestrator è·å–
                orchestrator=self.model_orchestrator
            )
            
            print(f"\nğŸ“Š Event Category: {event_analysis['category']}")
            print(f"ğŸ“ Dimensions: {len(event_analysis['dimensions'])}")
            
            # Get model assignments from analysis
            model_assignments = event_analysis["model_assignments"]
            
            # å°†å…¨é¢åˆ†æç»“æœæ·»åŠ åˆ°event_dataä¸­ï¼Œä¾›PromptBuilderå’ŒOutputFormatterä½¿ç”¨
            event_data["full_analysis"] = full_analysis
            # ã€é›†æˆã€‘æ·»åŠ ä¸–ç•Œæ¸©åº¦å’Œæ–°é—»æ‘˜è¦åˆ° event_dataï¼ˆä¾› prompt_builder å’Œ output_formatter ä½¿ç”¨ï¼‰
            # è½»é‡æè¿°æ¨¡å¼ï¼šworld_temp ç°åœ¨æ˜¯æè¿°å­—ç¬¦ä¸²
            event_data["world_temp"] = full_analysis.get("world_temp")  # æè¿°å­—ç¬¦ä¸²
            event_data["world_temp_data"] = full_analysis.get("world_temp_data")  # å®Œæ•´æ•°æ®
            event_data["world_sentiment_summary"] = full_analysis.get("world_sentiment_summary")
            event_data["news_summary"] = news_summary
            
            # Get available models (only those with API keys)
            all_models = list(model_assignments.keys())
            model_names = [
                model for model in all_models
                if model in self.model_orchestrator.get_available_models()
            ]
            
            if not model_names:
                await maybe_await(update.message.reply_text(
                    self.output_formatter.format_error(
                        "æ²¡æœ‰å¯ç”¨çš„ AI æ¨¡å‹ã€‚è¯·è‡³å°‘é…ç½®ä¸€ä¸ª API å¯†é’¥ã€‚"
                    ),
                    parse_mode="Markdown"
                ))
                return
            
            # Check if this is a multi-option event
            if event_data.get("is_multi_option", False):
                # Multi-option event: predict each option separately
                outcomes = event_data.get("outcomes", [])
                print(f"\nğŸ¯ å¤šé€‰é¡¹äº‹ä»¶æ£€æµ‹:")
                print(f"  is_multi_option: {event_data.get('is_multi_option', False)}")
                print(f"  outcomesæ•°é‡: {len(outcomes)}")
                if len(outcomes) == 0:
                    print(f"  âš ï¸ è­¦å‘Šï¼šå¤šé€‰é¡¹äº‹ä»¶ä½†outcomesä¸ºç©ºï¼")
                    print(f"  event_data keys: {list(event_data.keys())}")
                    # Try to reconstruct from markets if available
                    # This shouldn't happen, but let's add a fallback
                else:
                    print(f"  âœ… å‰3ä¸ªé€‰é¡¹: {[o.get('name', 'N/A') for o in outcomes[:3]]}")
                
                await maybe_await(update.message.reply_text(
                    f"ğŸ” æ£€æµ‹åˆ°å¤šé€‰é¡¹äº‹ä»¶ï¼Œå…±æœ‰ {len(outcomes)} ä¸ªé€‰é¡¹\n"
                    f"ğŸ¤– æ­£åœ¨ä¸ºæ¯ä¸ªé€‰é¡¹è¿›è¡Œé¢„æµ‹..."
                ))
                
                # Sequentially call models for each outcome
                outcome_predictions: Dict[str, Dict[str, Optional[Dict[str, Any]]]] = {}
                for outcome in outcomes:
                    outcome_name = outcome["name"]
                    print(f"\nğŸ¯ å¤„ç†é€‰é¡¹: {outcome_name}")
                    prompts = self._gather_multi_option_prompts(
                        event_data=event_data,
                        model_assignments=model_assignments,
                        model_names=model_names,
                        outcome=outcome
                    )
                    if not prompts:
                        print("   âš ï¸ æ— å¯ç”¨æ¨¡å‹ï¼Œä½¿ç”¨å¸‚åœºä»·æ ¼")
                        outcome_predictions[outcome_name] = {}
                        continue
                    
                    outcome_predictions[outcome_name] = await self._run_multi_option_models(
                        outcome_name=outcome_name,
                        prompts=prompts
                    )
                    await asyncio.sleep(0.5)
                
                # Fuse predictions for each outcome
                model_weights = {
                    model_name: self.model_orchestrator.get_model_weight(model_name)
                    for model_name in model_names
                }
                
                fused_outcomes: List[Dict[str, Any]] = []
                deepseek_reasoning: Optional[str] = None
                
                for outcome in outcomes:
                    outcome_name = outcome["name"]
                    outcome_results = outcome_predictions.get(outcome_name, {})
                    fused_outcome, deepseek_reasoning = self._fuse_multi_option_outcome(
                        outcome=outcome,
                        outcome_results=outcome_results,
                        model_weights=model_weights,
                        current_reasoning=deepseek_reasoning
                    )
                    fused_outcomes.append(fused_outcome)
                
                await self._finalize_multi_option_response(
                    update=update,
                    event_data=event_data,
                    fused_outcomes=fused_outcomes,
                    raw_outcomes=outcomes,
                    full_analysis=full_analysis,
                    deepseek_reasoning=deepseek_reasoning,
                    model_names=model_names
                )
            else:
                prompts = self._build_binary_prompts(
                    event_data=event_data,
                    model_assignments=model_assignments,
                    model_names=model_names
                )
                
                model_results = await self._call_binary_models(update, prompts)
                if model_results is None:
                    return
                
                await self._finalize_binary_prediction(
                    update=update,
                    event_data=event_data,
                    model_results=model_results,
                    model_names=model_names,
                    full_analysis=full_analysis
                )
            
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            self.logger.exception("handle_predict å¤„ç†å¼‚å¸¸: %s", error_msg)

            await maybe_await(update.message.reply_text(
                self.output_formatter.format_error(
                    f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {error_type}: {error_msg}"
                ),
                parse_mode="Markdown"
            ))
    
    async def handle_start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /start command."""
        welcome_message = """
ğŸ¤– *Polymarket é¢„æµ‹æœºå™¨äºº*

æˆ‘å¯ä»¥ä½¿ç”¨å¤šä¸ª AI æ¨¡å‹é¢„æµ‹ Polymarket äº‹ä»¶ï¼

*ä½¿ç”¨æ–¹æ³•:*
/predict <äº‹ä»¶æè¿°>

*ç¤ºä¾‹:*
/predict Sora ä¼šåœ¨ 10 æœˆ 31 æ—¥æˆä¸ºç¾å›½ Apple App Store å…è´¹åº”ç”¨æ’è¡Œæ¦œç¬¬ä¸€åå—ï¼Ÿ

æœºå™¨äººå°†ï¼š
1. ä» Polymarket è·å–å¸‚åœºæ•°æ®
2. æŸ¥è¯¢å¤šä¸ª AI æ¨¡å‹ï¼ˆDeepSeek + OpenRouterï¼‰
3. èåˆé¢„æµ‹ç»“æœä¸å¸‚åœºæ¦‚ç‡
4. æä¾›è¯¦ç»†çš„é¢„æµ‹æŠ¥å‘Š
        """
        await maybe_await(update.message.reply_text(
            welcome_message,
            parse_mode="Markdown"
        ))
    
    async def handle_ping(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /ping command for testing."""
        await maybe_await(update.message.reply_text("âœ… Bot æ­£å¸¸è¿è¡Œï¼"))
    
    async def handle_help(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle /help command."""
        help_message = """
*å‘½ä»¤:*
/start - å¯åŠ¨æœºå™¨äºº
/help - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
/predict <äº‹ä»¶> - é¢„æµ‹ä¸€ä¸ª Polymarket äº‹ä»¶

*å·¥ä½œåŸç†:*
æœºå™¨äººä½¿ç”¨å¤šä¸ª AI æ¨¡å‹çš„é›†æˆæ¥è¿›è¡Œé¢„æµ‹ï¼š
- DeepSeek: æ ¸å¿ƒé‡åŒ–æ¨ç†
- NVIDIA Nemotron: å¸‚åœºåˆ†æ
- DeepSeek (OpenRouter): é‡åŒ–æ¨ç†ä¸å¸‚åœºåˆ†æ

ç»“æœä¼šä¸ Polymarket å¸‚åœºæ¦‚ç‡èåˆï¼Œä»¥æé«˜å‡†ç¡®æ€§ã€‚
        """
        await maybe_await(update.message.reply_text(
            help_message,
            parse_mode="Markdown"
        ))


def list_models():
    """List all configured models and their versions."""
    from model_orchestrator import ModelOrchestrator
    
    orchestrator = ModelOrchestrator()
    
    print("=" * 80)
    print("ğŸ¤– å½“å‰é…ç½®çš„æ¨¡å‹ç‰ˆæœ¬".center(80))
    print("=" * 80)
    
    models_summary = orchestrator.get_active_models_summary()
    
    print(f"\n{'æ¨¡å‹åç§°':<25} {'æ¨¡å‹ID':<30} {'æ›´æ–°æ—¶é—´':<12} {'æƒé‡':<8}")
    print("-" * 80)
    
    for model_id, info in models_summary.items():
        display_name = info.get("display_name", model_id)
        last_updated = info.get("last_updated", "æœªçŸ¥")
        weight = info.get("weight", 0)
        print(f"{display_name:<25} {model_id:<30} {last_updated:<12} {weight:<8.1f}")
    
    print("\n" + "=" * 80)
    print("ğŸ“Š æ¨¡å‹ç»Ÿè®¡".center(80))
    print("=" * 80)
    print(f"æ€»æ¨¡å‹æ•°: {len(models_summary)}")
    
    # Show default model
    default_models = [
        model_id for model_id, info in orchestrator.MODELS.items()
        if info.get("is_default", False)
    ]
    if default_models:
        print(f"é»˜è®¤æ¨¡å‹: {', '.join(default_models)}")
    
    print("\n" + "=" * 80)


REQUIRED_ENV_VARS = (
    "TELEGRAM_BOT_TOKEN",
    "AICANAPI_KEY",
    "DEEPSEEK_API_KEY",
    "OPENROUTER_API_KEY",
    "NOTION_TOKEN",
    "NOTION_DB_ID"
    # POLYMARKET_API_KEY is optional - system works without it
)


def _validate_required_environment() -> None:
    """Ensure all critical environment variables exist before bootstrapping."""
    missing = [key for key in REQUIRED_ENV_VARS if not os.environ.get(key)]
    if missing:
        missing_list = ", ".join(missing)
        sys.exit(f"Error: Missing required environment variable(s): {missing_list}")


def main():
    """Main entry point."""
    load_dotenv()
    _validate_required_environment()
    
    # Check for --list-models command early to support offline diagnostics
    if len(sys.argv) > 1 and sys.argv[1] == "--list-models":
        list_models()
        return
    
    if not TELEGRAM_AVAILABLE:
        print("ğŸ›‘ Telegram ä¾èµ–æœªå®‰è£…ï¼Œæœºå™¨äººæ— æ³•å¯åŠ¨ã€‚è¯·è¿è¡Œ: pip install python-telegram-bot==13.15")
        print(f"   åŸå§‹é”™è¯¯: {TELEGRAM_IMPORT_ERROR}")
        return
    
    # ã€æ–°å¢ã€‘æ£€æŸ¥å¹¶æ›´æ–° LMArena æƒé‡ï¼ˆä»…åœ¨å¯åŠ¨æ—¶ï¼‰
    if LMARENA_UPDATE_AVAILABLE:
        try:
            if should_update():
                print(f"\n[LMArena] æ£€æµ‹åˆ°æƒé‡æ–‡ä»¶éœ€è¦æ›´æ–°ï¼Œå¼€å§‹åˆ·æ–°...")
                update_success = update_lmarena_weights()
                if not update_success:
                    print(f"[LMArena] æ‹‰å–å¤±è´¥ï¼Œä½¿ç”¨æ—§æƒé‡")
            else:
                print(f"[LMArena] æƒé‡æ–‡ä»¶ä»ç„¶æœ‰æ•ˆï¼Œè·³è¿‡æ›´æ–°")
        except Exception as e:
            print(f"âš ï¸ [LMArena] è‡ªåŠ¨æ›´æ–°æƒé‡æ—¶å‡ºé”™: {type(e).__name__}: {e}")
            print(f"   ç»§ç»­ä½¿ç”¨ç°æœ‰æƒé‡æ–‡ä»¶")
    
    token = os.getenv("TELEGRAM_BOT_TOKEN")
    
    if not token:
        print("Error: TELEGRAM_BOT_TOKEN not found in environment variables.")
        print("Please create a .env file with your Telegram bot token.")
        return
    
    # Create bot instance
    bot = ForecastingBot()
    
    # Create application
    try:
        # apscheduler æ—¶åŒºé—®é¢˜å·²åœ¨æ¨¡å—å¯¼å…¥æ—¶ä¿®è¡¥
        builder = Application.builder().token(token)
        application = builder.build()
        
        # Register handlers
        application.add_handler(CommandHandler("start", wrap_async_handler(bot.handle_start)))
        application.add_handler(CommandHandler("help", wrap_async_handler(bot.handle_help)))
        application.add_handler(CommandHandler("ping", wrap_async_handler(bot.handle_ping)))
        application.add_handler(CommandHandler("predict", wrap_async_handler(bot.handle_predict)))
        
        # Handle direct Polymarket URLs - check both text and entities
        async def handle_url_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
            """Handle messages containing Polymarket URLs."""
            print(f"\nğŸ” [URL Handler] æ”¶åˆ°æ¶ˆæ¯ï¼Œæ£€æŸ¥æ˜¯å¦ä¸º URL...")
            
            if not update.message:
                print(f"âš ï¸ [URL Handler] update.message ä¸ºç©º")
                return
            
            text = update.message.text or ""
            print(f"ğŸ“ [URL Handler] æ¶ˆæ¯æ–‡æœ¬: {text[:100]}...")
            print(f"ğŸ“ [URL Handler] æ¶ˆæ¯æ–‡æœ¬é•¿åº¦: {len(text)}")
            
            # Method 1: Check text content directly
            has_polymarket_url = False
            if text:
                try:
                    has_polymarket_url = 'polymarket.com' in text.lower()
                    if has_polymarket_url:
                        print(f"âœ… [URL Handler] ä»æ–‡æœ¬å†…å®¹æ£€æµ‹åˆ° Polymarket URL")
                except Exception as e:
                    print(f"âš ï¸ [URL Handler] æ£€æŸ¥æ–‡æœ¬å†…å®¹æ—¶å‡ºé”™: {e}")
            
            # Method 2: Check message entities (URL links, text links, etc.)
            if not has_polymarket_url and update.message.entities:
                print(f"ğŸ” [URL Handler] æ£€æŸ¥æ¶ˆæ¯å®ä½“ï¼Œæ•°é‡: {len(update.message.entities)}")
                try:
                    from telegram import MessageEntity
                    for entity in update.message.entities:
                        print(f"   - å®ä½“ç±»å‹: {entity.type}, offset: {entity.offset}, length: {entity.length}")
                        if entity.type in [MessageEntity.URL, MessageEntity.TEXT_LINK]:
                            # Extract URL from entity
                            if entity.type == MessageEntity.URL:
                                url_text = text[entity.offset:entity.offset + entity.length]
                                print(f"   âœ… æ‰¾åˆ° URL å®ä½“: {url_text[:80]}")
                            elif entity.type == MessageEntity.TEXT_LINK:
                                url_text = entity.url
                                print(f"   âœ… æ‰¾åˆ° TEXT_LINK å®ä½“: {url_text[:80]}")
                            else:
                                continue
                            
                            if url_text and 'polymarket.com' in url_text.lower():
                                has_polymarket_url = True
                                print(f"âœ… [URL Handler] ä»æ¶ˆæ¯å®ä½“æ£€æµ‹åˆ° URL: {url_text[:80]}")
                                break
                except Exception as e:
                    print(f"âš ï¸ [URL Handler] æ£€æŸ¥æ¶ˆæ¯å®ä½“æ—¶å‡ºé”™: {e}")
                    import traceback
                    traceback.print_exc()
            
            if has_polymarket_url:
                print(f"âœ… [URL Handler] æ£€æµ‹åˆ° Polymarket URLï¼Œå¼€å§‹å¤„ç†...")
                try:
                    await bot.handle_predict(update, context)
                except Exception as e:
                    print(f"âŒ [URL Handler] è°ƒç”¨ handle_predict æ—¶å‡ºé”™: {e}")
                    import traceback
                    traceback.print_exc()
            else:
                print(f"â„¹ï¸ [URL Handler] æœªæ£€æµ‹åˆ° Polymarket URLï¼Œè·³è¿‡å¤„ç†")
        
        # Add handler for URLs - register with lower priority (group=1)
        application.add_handler(
            MessageHandler(
                filters.TEXT & ~filters.COMMAND,
                wrap_async_handler(handle_url_message)
            ),
            group=1
        )
        
        # Add error handler
        async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
            """Log the error and send a message to the user."""
            import traceback
            error = context.error
            print(f"\nâŒ Exception while handling an update:")
            print(f"   é”™è¯¯ç±»å‹: {type(error).__name__}")
            print(f"   é”™è¯¯ä¿¡æ¯: {error}")
            traceback.print_exc()
            
            # Try to send error message to user if possible
            if update and hasattr(update, 'message') and update.message:
                try:
                    await maybe_await(context.bot.send_message(
                        chat_id=update.message.chat_id,
                        text=f"âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {type(error).__name__}\nè¯·ç¨åé‡è¯•æˆ–ä½¿ç”¨ /help æŸ¥çœ‹å¸®åŠ©ã€‚"
                    ))
                except:
                    pass
        
        application.add_error_handler(wrap_async_handler(error_handler))
        
        # Start bot
        print("=" * 50)
        print("ğŸ¤– Polymarket é¢„æµ‹æœºå™¨äºº")
        print("=" * 50)
        print(f"âœ… Bot Token: {token[:10]}...")
        print("âœ… æœºå™¨äººæ­£åœ¨å¯åŠ¨...")
        print("âœ… ç­‰å¾…æ¶ˆæ¯...")
        print("=" * 50)
        print("\nğŸ’¡ æç¤ºï¼šåœ¨ Telegram ä¸­æ‰¾åˆ°ä½ çš„ Bot å¹¶å‘é€ /start")
        print("=" * 50)
        
        application.run_polling(
            allowed_updates=Update.ALL_TYPES,
            drop_pending_updates=True
        )
    except Exception as e:
        print(f"âŒ å¯åŠ¨æœºå™¨äººæ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        print("\nè¯·æ£€æŸ¥ï¼š")
        print("1. Bot Token æ˜¯å¦æ­£ç¡®")
        print("2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("3. æ˜¯å¦èƒ½å¤Ÿè®¿é—® Telegram API")


def test_notion_write():
    """æµ‹è¯• Notion å†™å…¥åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯• Notion å†™å…¥åŠŸèƒ½")
    print("=" * 60)
    
    try:
        from notion_logger import NotionLogger
        
        notion_logger = NotionLogger(
            notion_token=os.getenv("NOTION_TOKEN"),
            database_id=os.getenv("NOTION_DB_ID")
        )
        
        if not notion_logger.enabled:
            print("âš ï¸ Notion Logger æœªå¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
            return
        
        print("âœ… Notion Logger å·²åˆå§‹åŒ–")
        
        # æµ‹è¯•æ•°æ®
        test_event_data = {
            "question": "Notion æµ‹è¯•å†™å…¥",
            "market_prob": 0.25,
            "category": "system",
            "rules": "å†™å…¥æµ‹è¯•"
        }
        
        test_fusion_result = {
            "model_only_prob": 0.35,
            "final_prob": 0.33,
            "summary": "æµ‹è¯•æ˜¯å¦èƒ½æˆåŠŸå†™å…¥ Notionã€‚",
            "model_versions": {
                "gpt-4o": {"display_name": "GPT-4o"},
                "claude-3-7-sonnet-latest": {"display_name": "Claude"}
            },
            "run_id": "test-001"
        }
        
        print(f"ğŸ“ æ­£åœ¨å†™å…¥æµ‹è¯•æ•°æ®...")
        result = notion_logger.log_prediction(
            event_data=test_event_data,
            fusion_result=test_fusion_result,
            full_analysis={"event_category": "system", "rules_summary": "å†™å…¥æµ‹è¯•"},
            outcomes=None,
            normalization_info=None,
            trade_signal=None
        )
        
        if result:
            print(f"âœ… æˆåŠŸå†™å…¥ Notion: {test_event_data.get('question')}")
            print(f"ğŸ’¡ è¯·å‰å¾€æ•°æ®åº“æŸ¥çœ‹: https://www.notion.so/{notion_logger.database_id}")
        else:
            print(f"âŒ å†™å…¥å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°æ¥è¿è¡Œæµ‹è¯•
    if len(sys.argv) > 1 and sys.argv[1] == "--test-notion":
        test_notion_write()
    else:
        main()
