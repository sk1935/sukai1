"""
OpenRouter åŠ©æ‰‹ - æ–°é—»æ‘˜è¦ç”Ÿæˆ

åŠŸèƒ½ï¼š
- ä½¿ç”¨ OpenRouter å…è´¹æ¨¡å‹ç”Ÿæˆæ–°é—»æ‘˜è¦
- è¾“å…¥ï¼šnews_cache çš„æœ€æ–°æ–°é—»ï¼ˆå‰ 10 æ¡ï¼‰
- è¾“å‡ºï¼šç»¼åˆæ‘˜è¦æ–‡æœ¬ï¼Œä¿å­˜åˆ° cache/news_summary.txt
"""
import asyncio
import os
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional, List, Dict
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

OPENROUTER_ASSISTANT_ENABLED = os.getenv("OPENROUTER_ASSISTANT_ENABLED", "false").lower() == "true"

# ç›¸å¯¹å¯¼å…¥ï¼ˆåŒç›®å½•ï¼‰
from src.news_cache import get_cached_news

try:
    from services.llm_clients.openrouter_layer import (
        call_openrouter_model,
        get_available_models,
        is_openrouter_available
    )
    OPENROUTER_LAYER_AVAILABLE = True
except Exception as import_err:
    OPENROUTER_LAYER_AVAILABLE = False
    print(f"âš ï¸ OpenRouter å±‚å¯¼å…¥å¤±è´¥ï¼Œè‡ªåŠ¨ç¦ç”¨: {import_err}")
    
    async def call_openrouter_model(*args, **kwargs):
        raise RuntimeError("OpenRouter layer unavailable")
    
    def get_available_models():
        return []
    
    def is_openrouter_available():
        return False

# ç¼“å­˜é…ç½®
CACHE_DIR = Path(__file__).parent.parent / "cache"
SUMMARY_FILE = CACHE_DIR / "news_summary.txt"


def ensure_cache_dir():
    """ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨"""
    CACHE_DIR.mkdir(parents=True, exist_ok=True)


def build_summary_prompt(news_list: List[Dict]) -> str:
    """
    æ„å»ºæ‘˜è¦ç”Ÿæˆæç¤ºè¯
    
    Args:
        news_list: æ–°é—»åˆ—è¡¨ï¼ˆå‰ 10 æ¡ï¼‰
    
    Returns:
        str: æ ¼å¼åŒ–çš„æç¤ºè¯
    """
    # æ„å»ºæ–°é—»æ–‡æœ¬
    news_text = ""
    for i, news in enumerate(news_list[:10], 1):
        news_text += f"{i}. [{news.get('source', 'Unknown')}] {news.get('title', '')}\n"
        if news.get('summary'):
            news_text += f"   æ‘˜è¦: {news.get('summary', '')[:100]}\n"
        news_text += "\n"
    
    prompt = f"""è¯·åˆ†æä»¥ä¸‹å…¨çƒæ–°é—»ï¼Œç”Ÿæˆä¸€ä»½ç»¼åˆæ‘˜è¦ã€‚

è¦æ±‚ï¼š
1. æ€»ç»“ä¸»è¦è¯é¢˜è¶‹åŠ¿ï¼ˆç”¨2-3å¥è¯ï¼‰
2. ç”¨ä¸€å¥è¯æè¿°"å½“å‰å…¨çƒæƒ…ç»ªåŸºè°ƒ"

æ–°é—»åˆ—è¡¨ï¼š
{news_text}

è¯·ç”¨ä¸­æ–‡è¾“å‡ºï¼Œæ ¼å¼ï¼š
ã€ä¸»è¦è¯é¢˜è¶‹åŠ¿ã€‘
...
ã€å…¨çƒæƒ…ç»ªåŸºè°ƒã€‘
...
"""
    
    return prompt


async def generate_news_summary(force_refresh: bool = False) -> Optional[str]:
    """
    ç”Ÿæˆæ–°é—»æ‘˜è¦
    
    Args:
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆå¿½ç•¥å·²å­˜åœ¨çš„æ‘˜è¦ï¼‰
    
    Returns:
        str: ç”Ÿæˆçš„æ‘˜è¦æ–‡æœ¬ï¼Œå¤±è´¥è¿”å› None
    """
    if not OPENROUTER_ASSISTANT_ENABLED:
        print("ğŸ›‘ [OPENROUTER_ASSISTANT] åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡æ‘˜è¦ç”Ÿæˆ")
        return None
    
    if not OPENROUTER_LAYER_AVAILABLE:
        print("ğŸ›‘ [OPENROUTER_ASSISTANT] OpenRouter å±‚ä¸å¯ç”¨")
        return None
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ‘˜è¦ä¸”æœªè¿‡æœŸ
    if not force_refresh and SUMMARY_FILE.exists():
        try:
            # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´ï¼ˆå¦‚æœå°äº6å°æ—¶ï¼Œç›´æ¥è¿”å›ï¼‰
            file_time = datetime.fromtimestamp(SUMMARY_FILE.stat().st_mtime, tz=timezone.utc)
            now = datetime.now(timezone.utc)
            
            if (now - file_time).total_seconds() < 6 * 3600:  # 6å°æ—¶æœ‰æ•ˆæœŸ
                print(f"âœ… ä½¿ç”¨ç¼“å­˜çš„æ–°é—»æ‘˜è¦ï¼ˆå‰©ä½™æœ‰æ•ˆæœŸï¼š{int((6 * 3600 - (now - file_time).total_seconds()) / 3600)} å°æ—¶ï¼‰")
                with open(SUMMARY_FILE, 'r', encoding='utf-8') as f:
                    return f.read()
        except Exception as e:
            print(f"âš ï¸ è¯»å–ç¼“å­˜æ‘˜è¦å¤±è´¥: {e}")
    
    # æ£€æŸ¥ OpenRouter æ˜¯å¦å¯ç”¨
    if not is_openrouter_available():
        print("âš ï¸ OpenRouter API ä¸å¯ç”¨ï¼Œè·³è¿‡æ‘˜è¦ç”Ÿæˆ")
        return None
    
    # è·å–å¯ç”¨æ¨¡å‹
    available_models = get_available_models()
    if not available_models:
        print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„ OpenRouter æ¨¡å‹")
        return None
    
    # è·å–ç¼“å­˜çš„æ–°é—»
    news_list = get_cached_news()
    if not news_list:
        print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„æ–°é—»æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦")
        return None
    
    print(f"ğŸ“ å¼€å§‹ç”Ÿæˆæ–°é—»æ‘˜è¦ï¼ˆä½¿ç”¨ {len(news_list)} æ¡æ–°é—»ï¼‰...")
    
    # æ„å»ºæç¤ºè¯
    prompt = build_summary_prompt(news_list)
    
    # å°è¯•å¤šä¸ªæ¨¡å‹ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
    models_to_try = [
        "meta-llama/llama-3-70b-instruct",  # é¦–é€‰ï¼šLlama-3-70B
        "mistralai/mistral-7b-instruct",   # å¤‡é€‰ï¼šMistral-7B
        "yi-large/yi-1.5-chat"            # å¤‡é€‰ï¼šYi-Large
    ]
    
    summary = None
    
    for model_name in models_to_try:
        if model_name not in available_models:
            continue
        
        try:
            print(f"ğŸ¤– å°è¯•ä½¿ç”¨æ¨¡å‹: {model_name}")
            
            # å¯¹äºæ‘˜è¦ä»»åŠ¡ï¼Œæˆ‘ä»¬éœ€è¦ç›´æ¥è·å–åŸå§‹æ–‡æœ¬å“åº”
            # è°ƒç”¨ OpenRouter API è·å–åŸå§‹å“åº”
            api_key = os.getenv("OPENROUTER_API_KEY")
            if not api_key:
                print("âš ï¸ OPENROUTER_API_KEY æœªè®¾ç½®")
                continue
            
            import httpx
            timeout_seconds = 35.0
            
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://polymarket-predictor.com",
                "X-Title": "Polymarket AI Predictor"
            }
            
            payload = {
                "model": model_name,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 1000  # å¢åŠ  token é™åˆ¶ä»¥è·å–å®Œæ•´æ‘˜è¦
            }
            
            async with httpx.AsyncClient(timeout=httpx.Timeout(timeout_seconds)) as client:
                response = await client.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    json=payload,
                    headers=headers
                )
                
                if response.status_code == 200:
                    data = response.json()
                    content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                    
                    if content:
                        summary = content.strip()
                        print(f"âœ… æˆåŠŸä½¿ç”¨ {model_name} ç”Ÿæˆæ‘˜è¦ï¼ˆ{len(summary)} å­—ç¬¦ï¼‰")
                        break
                    else:
                        print(f"âš ï¸ {model_name} è¿”å›ç©ºå†…å®¹")
                else:
                    print(f"âŒ {model_name} API é”™è¯¯: {response.status_code}")
                    error_text = response.text[:200]
                    print(f"   é”™è¯¯è¯¦æƒ…: {error_text}")
                    
        except Exception as e:
            print(f"âš ï¸ {model_name} è°ƒç”¨å¤±è´¥: {type(e).__name__}: {e}")
            continue
    
    if not summary:
        print("âŒ æ‰€æœ‰æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦")
        return None
    
    # ä¿å­˜æ‘˜è¦åˆ°æ–‡ä»¶
    try:
        ensure_cache_dir()
        with open(SUMMARY_FILE, 'w', encoding='utf-8') as f:
            f.write(summary)
        
        print(f"âœ… æ–°é—»æ‘˜è¦å·²ä¿å­˜: {SUMMARY_FILE}")
        return summary
        
    except Exception as e:
        print(f"âŒ ä¿å­˜æ‘˜è¦å¤±è´¥: {e}")
        return summary  # å³ä½¿ä¿å­˜å¤±è´¥ï¼Œä¹Ÿè¿”å›æ‘˜è¦å†…å®¹


async def get_news_summary() -> Optional[str]:
    """
    è·å–æ–°é—»æ‘˜è¦ï¼ˆä¼˜å…ˆä»ç¼“å­˜è¯»å–ï¼‰
    
    Returns:
        str: æ‘˜è¦æ–‡æœ¬ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–è¿‡æœŸè¿”å› None
    """
    if not OPENROUTER_ASSISTANT_ENABLED:
        return None
    return await generate_news_summary(force_refresh=False)


# å¯¼å‡ºå‡½æ•°
__all__ = [
    "generate_news_summary",
    "get_news_summary",
    "build_summary_prompt",
    "SUMMARY_FILE"
]
