"""
æ¶ˆèå®éªŒæ¨¡å—ï¼ˆAblation Study Moduleï¼‰
æ”¯æŒé€šè¿‡é…ç½®å¼€å…³è¿›è¡Œä¸åŒå®éªŒå˜ä½“çš„æµ‹è¯•
"""
import os
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dotenv import load_dotenv

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from fusion_engine import FusionEngine
from metrics import (
    brier_score, log_loss_score, ece_score, sharpness,
    paired_t_test, compute_all_metrics
)

load_dotenv()


class ExperimentConfig:
    """å®éªŒé…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_path: Optional[Path] = None):
        """
        åˆå§‹åŒ–å®éªŒé…ç½®
        
        Args:
            config_path: YAMLé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.config = {}
        
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        self._load_from_env()
        
        # ä»YAMLæ–‡ä»¶è¯»å–é…ç½®ï¼ˆå¦‚æœæä¾›ï¼‰
        if config_path is None:
            # é»˜è®¤è·¯å¾„
            default_path = Path(__file__).parent.parent / "config" / "experiments.yaml"
            if default_path.exists():
                config_path = default_path
        
        if config_path and config_path.exists():
            self._load_from_yaml(config_path)
        
        # è®¾ç½®é»˜è®¤å€¼
        self._set_defaults()
    
    def _load_from_env(self):
        """ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®"""
        self.config = {
            "FUSION": {
                "consensus_coef": os.getenv("FUSION_CONSENSUS_COEF", "true").lower() == "true",
                "market_bias": os.getenv("FUSION_MARKET_BIAS", "true").lower() == "true",
                "demarket_penalty": os.getenv("FUSION_DEMARKET_PENALTY", "true").lower() == "true"
            },
            "CALIBRATION": {
                "post_calibration": os.getenv("CALIBRATION_POST_CALIBRATION", "none").lower()
            },
            "SENTIMENT": {
                "reddit_bluesky": os.getenv("SENTIMENT_REDDIT_BLUESKY", "false").lower() == "true"
            }
        }
    
    def _load_from_yaml(self, config_path: Path):
        """ä»YAMLæ–‡ä»¶è¯»å–é…ç½®"""
        try:
            import yaml
            with open(config_path, 'r', encoding='utf-8') as f:
                yaml_config = yaml.safe_load(f)
                if yaml_config:
                    # åˆå¹¶é…ç½®ï¼ˆYAMLä¼˜å…ˆçº§æ›´é«˜ï¼‰
                    self._deep_update(self.config, yaml_config)
        except ImportError:
            print("âš ï¸ PyYAMLæœªå®‰è£…ï¼Œè·³è¿‡YAMLé…ç½®åŠ è½½ï¼ˆå¯é€‰ä¾èµ–ï¼‰")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½YAMLé…ç½®å¤±è´¥: {e}")
    
    def _deep_update(self, base: dict, update: dict):
        """æ·±åº¦åˆå¹¶å­—å…¸"""
        for key, value in update.items():
            if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                self._deep_update(base[key], value)
            else:
                base[key] = value
    
    def _set_defaults(self):
        """è®¾ç½®é»˜è®¤å€¼"""
        defaults = {
            "FUSION": {
                "consensus_coef": True,
                "market_bias": True,
                "demarket_penalty": True
            },
            "CALIBRATION": {
                "post_calibration": "none"
            },
            "SENTIMENT": {
                "reddit_bluesky": False
            }
        }
        
        for section, values in defaults.items():
            if section not in self.config:
                self.config[section] = {}
            for key, default_value in values.items():
                if key not in self.config[section]:
                    self.config[section][key] = default_value
    
    def get(self, section: str, key: str, default=None):
        """è·å–é…ç½®å€¼"""
        return self.config.get(section, {}).get(key, default)
    
    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸ï¼ˆä¾›FusionEngineä½¿ç”¨ï¼‰"""
        return self.config.copy()


def run_ablation(dataset_path: str, config: Optional[ExperimentConfig] = None,
                 baseline_config: Optional[Dict] = None) -> pd.DataFrame:
    """
    è¿è¡Œæ¶ˆèå®éªŒ
    
    Args:
        dataset_path: CSVæ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«åˆ—ï¼š
            - market_id: å¸‚åœºID
            - resolved_outcome: çœŸå®ç»“æœï¼ˆ0/1 æˆ–ç±»åˆ«ç´¢å¼•ï¼‰
            - ai_prob: AIé¢„æµ‹æ¦‚ç‡ï¼ˆå•å€¼æˆ–æ¦‚ç‡åˆ†å¸ƒï¼‰
            - market_prob: å¸‚åœºä»·æ ¼ï¼ˆå¯é€‰ï¼‰
            - timestamp: æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰
        config: å®éªŒé…ç½®ï¼ˆé»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰
        baseline_config: åŸºçº¿é…ç½®ï¼ˆé»˜è®¤ï¼šæ‰€æœ‰å¼€å…³ä¸ºTrueï¼‰
    
    Returns:
        DataFrameï¼ŒåŒ…å«å„å˜ä½“çš„è¯„ä¼°æŒ‡æ ‡ï¼š
        [variant, brier, logloss, ece, sharpness, N, p_value]
    """
    # è¯»å–æ•°æ®é›†
    df = pd.read_csv(dataset_path)
    print(f"ğŸ“Š è¯»å–æ•°æ®é›†: {len(df)} æ¡è®°å½•")
    
    if config is None:
        config = ExperimentConfig()
    
    if baseline_config is None:
        baseline_config = {
            "consensus_coef": True,
            "market_bias": True,
            "demarket_penalty": True,
            "post_calibration": "none"
        }
    
    # å®šä¹‰å®éªŒå˜ä½“
    variants = [
        {
            "name": "baseline",
            "consensus_coef": baseline_config.get("consensus_coef", True),
            "market_bias": baseline_config.get("market_bias", True),
            "demarket_penalty": baseline_config.get("demarket_penalty", True),
            "post_calibration": baseline_config.get("post_calibration", "none")
        },
        {
            "name": "no_consensus_coef",
            "consensus_coef": False,
            "market_bias": True,
            "demarket_penalty": True,
            "post_calibration": "none"
        },
        {
            "name": "no_market_bias",
            "consensus_coef": True,
            "market_bias": False,
            "demarket_penalty": True,
            "post_calibration": "none"
        },
        {
            "name": "no_demarket_penalty",
            "consensus_coef": True,
            "market_bias": True,
            "demarket_penalty": False,
            "post_calibration": "none"
        },
        {
            "name": "with_binning_calibration",
            "consensus_coef": True,
            "market_bias": True,
            "demarket_penalty": True,
            "post_calibration": "binning"
        },
        {
            "name": "with_platt_calibration",
            "consensus_coef": True,
            "market_bias": True,
            "demarket_penalty": True,
            "post_calibration": "platt"
        }
    ]
    
    results = []
    baseline_metrics = None
    
    for variant in variants:
        print(f"\nğŸ§ª æµ‹è¯•å˜ä½“: {variant['name']}")
        
        # åˆ›å»ºå˜ä½“é…ç½®
        variant_config = ExperimentConfig()
        variant_config.config["FUSION"]["consensus_coef"] = variant["consensus_coef"]
        variant_config.config["FUSION"]["market_bias"] = variant["market_bias"]
        variant_config.config["FUSION"]["demarket_penalty"] = variant["demarket_penalty"]
        variant_config.config["CALIBRATION"]["post_calibration"] = variant["post_calibration"]
        
        # åˆ›å»ºä½¿ç”¨è¯¥é…ç½®çš„FusionEngine
        fusion_engine = FusionEngine(experiment_config=variant_config)
        
        # è®¡ç®—è¯¥å˜ä½“çš„æŒ‡æ ‡
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ¨¡æ‹Ÿèåˆè¿‡ç¨‹ï¼Œå®é™…åº”è¯¥è°ƒç”¨FusionEngine
        # ä¸ºç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾dfä¸­å·²æœ‰èåˆåçš„æ¦‚ç‡
        variant_df = df.copy()
        
        # å¦‚æœdfä¸­æœ‰"ai_prob"ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™éœ€è¦æ¨¡æ‹Ÿèåˆ
        if "final_prob" in variant_df.columns:
            p_pred = variant_df["final_prob"].values
        elif "ai_prob" in variant_df.columns:
            # ç®€å•å¤„ç†ï¼šå¦‚æœæœ‰market_probï¼Œèåˆï¼›å¦åˆ™ç›´æ¥ç”¨ai_prob
            if "market_prob" in variant_df.columns:
                # æ¨¡æ‹Ÿèåˆï¼š80% AI + 20% å¸‚åœº
                p_pred = 0.8 * variant_df["ai_prob"].values + 0.2 * variant_df["market_prob"].values
            else:
                p_pred = variant_df["ai_prob"].values
        else:
            raise ValueError("æ•°æ®é›†å¿…é¡»åŒ…å« 'final_prob' æˆ– 'ai_prob' åˆ—")
        
        y_true = variant_df["resolved_outcome"].values
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = compute_all_metrics(y_true, p_pred)
        
        # é…ç½®å·²ä¿å­˜åœ¨variant_configä¸­ï¼Œä¸éœ€è¦æ¢å¤
        
        result_row = {
            "variant": variant["name"],
            "brier": metrics["brier"],
            "logloss": metrics["log_loss"],
            "ece": metrics["ece"],
            "sharpness": metrics["sharpness"],
            "N": len(variant_df)
        }
        
        # å¦‚æœæ˜¯åŸºçº¿ï¼Œä¿å­˜é¢„æµ‹æ¦‚ç‡ç”¨äºåç»­æ¯”è¾ƒ
        if variant["name"] == "baseline":
            baseline_preds = p_pred.copy()
            baseline_metrics = metrics
            result_row["p_value"] = None
        else:
            # ä¸åŸºçº¿åšé…å¯¹tæ£€éªŒ
            # ä½¿ç”¨Brier Scoreä½œä¸ºæ ·æœ¬å¾—åˆ†
            baseline_scores = _compute_sample_scores(y_true, baseline_preds)
            variant_scores = _compute_sample_scores(y_true, p_pred)
            _, p_value = paired_t_test(baseline_scores, variant_scores)
            result_row["p_value"] = p_value
        
        results.append(result_row)
        
        print(f"   Brier: {metrics['brier']:.4f}, LogLoss: {metrics['log_loss']:.4f}, "
              f"ECE: {metrics['ece']:.4f}, Sharpness: {metrics['sharpness']:.4f}")
        if result_row["p_value"]:
            print(f"   vs åŸºçº¿ p-value: {result_row['p_value']:.4f}")
    
    results_df = pd.DataFrame(results)
    return results_df


def _compute_sample_scores(y_true: np.ndarray, p_pred: np.ndarray) -> np.ndarray:
    """
    è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„Brier Scoreï¼ˆç”¨äºé…å¯¹tæ£€éªŒï¼‰
    
    Args:
        y_true: çœŸå®æ ‡ç­¾
        p_pred: é¢„æµ‹æ¦‚ç‡
    
    Returns:
        æ¯ä¸ªæ ·æœ¬çš„Brier Score
    """
    return (y_true - p_pred) ** 2


def print_ablation_table(results_df: pd.DataFrame):
    """æ‰“å°æ ¼å¼åŒ–çš„æ¶ˆèå®éªŒç»“æœè¡¨"""
    print("\n" + "=" * 80)
    print("ğŸ§ª æ¶ˆèå®éªŒç»“æœ".center(80))
    print("=" * 80)
    
    print(f"\n{'å˜ä½“':<25} {'Brier':<10} {'LogLoss':<10} {'ECE':<10} {'Sharpness':<10} {'N':<8} {'p-value':<10}")
    print("-" * 80)
    
    for _, row in results_df.iterrows():
        p_val_str = f"{row['p_value']:.4f}" if row['p_value'] is not None else "-"
        marker = " *" if row['p_value'] and row['p_value'] < 0.05 else ""
        
        print(f"{row['variant']:<25} {row['brier']:<10.4f} {row['logloss']:<10.4f} "
              f"{row['ece']:<10.4f} {row['sharpness']:<10.4f} {int(row['N']):<8} "
              f"{p_val_str:<10}{marker}")
    
    print("\n* p < 0.05 (ç›¸å¯¹äºåŸºçº¿)")
    print("=" * 80)

