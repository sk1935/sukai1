"""
OpenRouter Layerï¼šå…è´¹æ¨¡å‹è°ƒç”¨å±‚

åŠŸèƒ½ï¼š
- ä½¿ç”¨ OpenRouter API è°ƒç”¨å…è´¹æ¨¡å‹
- ä»…å…è®¸ç™½åå•å†…çš„æ¨¡å‹ï¼ˆé˜²æ­¢è¯¯è°ƒç”¨ä»˜è´¹æ¨¡å‹ï¼‰
- å¼‚æ­¥è°ƒç”¨ã€å¼‚å¸¸å¤„ç†ã€è¶…æ—¶æ§åˆ¶
- JSON æ ¼å¼æ¸…æ´—å’Œæ ‡å‡†åŒ–è¿”å›

è¾“å…¥ï¼šæ¨¡å‹åç§°ã€æç¤ºè¯
è¾“å‡ºï¼šæ ‡å‡†é¢„æµ‹ç»“æœå­—å…¸ {probability, confidence, reasoning}
"""
import os
import json
import re
from typing import Dict, Optional
from datetime import datetime
from dotenv import load_dotenv

# ä½¿ç”¨ httpx æ›¿ä»£ aiohttpï¼ˆæ›´ç°ä»£çš„å¼‚æ­¥ HTTP å®¢æˆ·ç«¯ï¼‰
import httpx
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)

load_dotenv()

# å…è´¹æ¨¡å‹ç™½åå•ï¼ˆOpenRouterï¼‰
FREE_MODELS = [
    "mistralai/mistral-7b-instruct",
    "meta-llama/llama-3-70b-instruct",
    "yi-large/yi-1.5-chat",
    "nousresearch/hermes-3-llama-3-8b",
    "openchat/openchat-3.5"
]

# OpenRouter API ç«¯ç‚¹
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"

# é»˜è®¤è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
DEFAULT_TIMEOUT = 30.0

# æ¨¡å‹è¶…æ—¶é…ç½®ï¼ˆåŸºäºå®é™…å“åº”é€Ÿåº¦ï¼‰
MODEL_TIMEOUTS = {
    "mistralai/mistral-7b-instruct": 25.0,
    "meta-llama/llama-3-70b-instruct": 35.0,
    "yi-large/yi-1.5-chat": 30.0,
    "nousresearch/hermes-3-llama-3-8b": 25.0,
    "openchat/openchat-3.5": 25.0
}


class ModelPrediction:
    """
    æ ‡å‡†æ¨¡å‹é¢„æµ‹ç»“æœå¯¹è±¡ï¼ˆç”¨äºç±»å‹æç¤ºï¼‰
    
    å®é™…è¿”å›ä¸ºå­—å…¸æ ¼å¼ï¼Œä¸ç°æœ‰ç³»ç»Ÿä¿æŒä¸€è‡´
    """
    def __init__(self, probability: float, confidence: str, reasoning: str):
        self.probability = probability
        self.confidence = confidence
        self.reasoning = reasoning
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ˆä¸ç°æœ‰ç³»ç»Ÿå…¼å®¹ï¼‰"""
        return {
            "probability": self.probability,
            "confidence": self.confidence,
            "reasoning": self.reasoning
        }


def validate_model(model: str) -> bool:
    """
    éªŒè¯æ¨¡å‹æ˜¯å¦åœ¨ç™½åå•ä¸­
    
    Args:
        model: æ¨¡å‹åç§°
        
    Returns:
        True if model is in whitelist, False otherwise
    """
    return model in FREE_MODELS


def get_model_timeout(model: str) -> float:
    """
    è·å–æ¨¡å‹çš„è‡ªé€‚åº”è¶…æ—¶æ—¶é—´
    
    Args:
        model: æ¨¡å‹åç§°
        
    Returns:
        è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    """
    return MODEL_TIMEOUTS.get(model, DEFAULT_TIMEOUT)


def clean_json_response(content: str) -> Optional[Dict]:
    """
    æ¸…æ´—å’Œè§£æ JSON æ ¼å¼çš„æ¨¡å‹å“åº”
    
    Args:
        content: åŸå§‹å“åº”å†…å®¹
        
    Returns:
        è§£æåçš„ JSON å­—å…¸ï¼Œæˆ– None å¦‚æœè§£æå¤±è´¥
    """
    if not content or not content.strip():
        return None
    
    try:
        original_content = content.strip()
        
        # æå– JSON ä»£ç å—
        if "```json" in content:
            start = content.find("```json") + 7
            end = content.find("```", start)
            if end != -1:
                content = content[start:end].strip()
        elif "```" in content:
            start = content.find("```") + 3
            end = content.find("```", start)
            if end != -1:
                content = content[start:end].strip()
        
        # æŸ¥æ‰¾ JSON å¯¹è±¡
        start_brace = content.find("{")
        end_brace = content.rfind("}")
        if start_brace != -1 and end_brace != -1 and end_brace > start_brace:
            content = content[start_brace:end_brace + 1]
        
        # è§£æ JSON
        data = json.loads(content)
        
        # éªŒè¯å’Œæ ‡å‡†åŒ–å­—æ®µ
        # æ”¯æŒå¤šç§å¯èƒ½çš„å­—æ®µå
        prob = None
        for key in ["prob_yes", "probability", "prob", "prediction"]:
            if key in data:
                prob = float(data.get(key))
                break
        
        if prob is None:
            # å°è¯•ä»æ–‡æœ¬ä¸­æå–
            prob_match = re.search(r'(?:probability|prob_yes|prediction)[":\s]+(\d+\.?\d*)', original_content, re.IGNORECASE)
            if prob_match:
                prob = float(prob_match.group(1))
            else:
                prob = 50.0  # é»˜è®¤å€¼
        
        # é™åˆ¶æ¦‚ç‡èŒƒå›´
        prob = max(0.0, min(100.0, prob))
        
        # è·å–ç½®ä¿¡åº¦
        confidence = data.get("confidence", "medium").lower()
        if confidence not in ["low", "medium", "high"]:
            confidence = "medium"
        
        # è·å–ç†ç”±ï¼ˆæ”¯æŒå¤šç§å­—æ®µåï¼‰
        reasoning = (
            data.get("rationale") or 
            data.get("reasoning") or 
            data.get("explanation") or 
            data.get("reason") or
            "No reasoning provided."
        )
        
        # æˆªæ–­è¿‡é•¿çš„ç†ç”±
        if len(reasoning) > 200:
            reasoning = reasoning[:197] + "..."
        
        return {
            "probability": prob,
            "confidence": confidence,
            "reasoning": reasoning
        }
        
    except json.JSONDecodeError as e:
        print(f"âš ï¸ [OpenRouter] JSON decode error: {e}")
        # å°è¯•ä»æ–‡æœ¬ä¸­æå–æ¦‚ç‡
        prob_match = re.search(r'(?:probability|prob_yes|prediction)[":\s]+(\d+\.?\d*)', original_content, re.IGNORECASE)
        if prob_match:
            try:
                prob = float(prob_match.group(1))
                prob = max(0.0, min(100.0, prob))
                print(f"âœ… [OpenRouter] Extracted probability from text: {prob}%")
                return {
                    "probability": prob,
                    "confidence": "medium",
                    "reasoning": "Parsed from unstructured response."
                }
            except:
                pass
        return None
        
    except Exception as e:
        print(f"âš ï¸ [OpenRouter] Error cleaning JSON response: {e}")
        return None


@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type((httpx.TimeoutException, httpx.NetworkError, httpx.RequestError))
)
async def call_openrouter_model(model: str, prompt: str) -> Optional[Dict]:
    """
    è°ƒç”¨ OpenRouter API çš„å¼‚æ­¥å‡½æ•°
    
    Args:
        model: æ¨¡å‹åç§°ï¼ˆå¿…é¡»åœ¨ FREE_MODELS ç™½åå•ä¸­ï¼‰
        prompt: æç¤ºè¯
        
    Returns:
        æ ‡å‡†é¢„æµ‹ç»“æœå­—å…¸ {probability, confidence, reasoning}ï¼Œæˆ– None å¦‚æœå¤±è´¥
        
    Raises:
        ValueError: å¦‚æœæ¨¡å‹ä¸åœ¨ç™½åå•ä¸­
    """
    # éªŒè¯æ¨¡å‹åœ¨ç™½åå•ä¸­
    if not validate_model(model):
        raise ValueError(
            f"æ¨¡å‹ '{model}' ä¸åœ¨å…è´¹æ¨¡å‹ç™½åå•ä¸­ã€‚"
            f"å…è®¸çš„æ¨¡å‹: {', '.join(FREE_MODELS)}"
        )
    
    # è·å– API å¯†é’¥
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        print("âš ï¸ [OpenRouter] OPENROUTER_API_KEY æœªè®¾ç½®ï¼Œè·³è¿‡è°ƒç”¨")
        return None
    
    # è·å–è¶…æ—¶æ—¶é—´
    timeout_seconds = get_model_timeout(model)
    
    # æ„å»ºè¯·æ±‚å¤´
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://polymarket-predictor.com",  # Optional: for analytics
        "X-Title": "Polymarket AI Predictor"  # Optional: for analytics
    }
    
    # æ„å»ºè¯·æ±‚ä½“
    payload = {
        "model": model,
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7,
        "max_tokens": 500
    }
    
    print(f"ğŸ“¡ [OpenRouter] Calling {model} (timeout: {timeout_seconds}s)")
    
    try:
        # ä½¿ç”¨ httpx.AsyncClient è¿›è¡Œå¼‚æ­¥è°ƒç”¨
        async with httpx.AsyncClient(timeout=httpx.Timeout(timeout_seconds)) as client:
            response = await client.post(
                OPENROUTER_API_URL,
                json=payload,
                headers=headers
            )
            
            if response.status_code == 200:
                data = response.json()
                content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                
                if not content:
                    print(f"âš ï¸ [OpenRouter] {model} è¿”å›ç©ºå†…å®¹")
                    return None
                
                print(f"âœ… [OpenRouter] {model} responded: {content[:100]}...")
                
                # æ¸…æ´—å’Œè§£æ JSON
                result = clean_json_response(content)
                
                if result:
                    print(f"âœ… [OpenRouter] {model} parsed successfully: prob={result.get('probability')}%")
                else:
                    print(f"âš ï¸ [OpenRouter] {model} response parsing failed")
                
                return result
            else:
                error_text = response.text
                print(f"âŒ [OpenRouter] API error for {model}: {response.status_code}")
                print(f"Error details: {error_text[:500]}")
                return None
                
    except httpx.TimeoutException:
        print(f"â±ï¸ [OpenRouter] {model} timeout after {timeout_seconds}s")
        # è¿”å›é»˜è®¤å€¼è€Œä¸æ˜¯ Noneï¼Œè®©ç³»ç»Ÿå¯ä»¥ç»§ç»­
        return {
            "probability": 50.0,
            "confidence": "low",
            "reasoning": f"OpenRouter timeout after {timeout_seconds}s"
        }
    except httpx.NetworkError as e:
        print(f"ğŸŒ [OpenRouter] Network error calling {model}: {type(e).__name__}: {e}")
        raise  # è®© tenacity é‡è¯•
    except httpx.RequestError as e:
        print(f"âŒ [OpenRouter] Request error calling {model}: {type(e).__name__}: {e}")
        raise  # è®© tenacity é‡è¯•
    except Exception as e:
        print(f"âŒ [OpenRouter] Unexpected error calling {model}: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return None


async def call_multiple_openrouter_models(
    models: list[str],
    prompt: str
) -> Dict[str, Optional[Dict]]:
    """
    å¹¶å‘è°ƒç”¨å¤šä¸ª OpenRouter æ¨¡å‹
    
    Args:
        models: æ¨¡å‹åç§°åˆ—è¡¨
        prompt: æç¤ºè¯
        
    Returns:
        å­—å…¸æ˜ å°„ model_name -> é¢„æµ‹ç»“æœ
    """
    import asyncio
    
    # è¿‡æ»¤æ‰ä¸åœ¨ç™½åå•ä¸­çš„æ¨¡å‹
    valid_models = [m for m in models if validate_model(m)]
    invalid_models = [m for m in models if m not in valid_models]
    
    if invalid_models:
        print(f"âš ï¸ [OpenRouter] ä»¥ä¸‹æ¨¡å‹ä¸åœ¨ç™½åå•ä¸­ï¼Œå°†è¢«å¿½ç•¥: {', '.join(invalid_models)}")
    
    if not valid_models:
        print("âš ï¸ [OpenRouter] æ²¡æœ‰æœ‰æ•ˆçš„æ¨¡å‹å¯è°ƒç”¨")
        return {}
    
    # å¹¶å‘è°ƒç”¨æ‰€æœ‰æ¨¡å‹
    tasks = {model: call_openrouter_model(model, prompt) for model in valid_models}
    results = await asyncio.gather(*tasks.values(), return_exceptions=True)
    
    # ç»„è£…ç»“æœå­—å…¸
    result_dict = {}
    for i, (model, result) in enumerate(zip(tasks.keys(), results)):
        if isinstance(result, Exception):
            print(f"âŒ [OpenRouter] {model} è°ƒç”¨å¼‚å¸¸: {type(result).__name__}: {result}")
            result_dict[model] = None
        else:
            result_dict[model] = result
    
    return result_dict


# ä¾¿æ·å‡½æ•°ï¼šè·å–æ‰€æœ‰å¯ç”¨çš„å…è´¹æ¨¡å‹åˆ—è¡¨
def get_available_models() -> list[str]:
    """
    è·å–æ‰€æœ‰å¯ç”¨çš„å…è´¹æ¨¡å‹åˆ—è¡¨
    
    Returns:
        æ¨¡å‹åç§°åˆ—è¡¨
    """
    return FREE_MODELS.copy()


# ä¾¿æ·å‡½æ•°ï¼šæ£€æŸ¥ OpenRouter æ˜¯å¦å¯ç”¨
def is_openrouter_available() -> bool:
    """
    æ£€æŸ¥ OpenRouter æ˜¯å¦å¯ç”¨ï¼ˆAPI å¯†é’¥æ˜¯å¦é…ç½®ï¼‰
    
    Returns:
        True if API key is configured, False otherwise
    """
    return bool(os.getenv("OPENROUTER_API_KEY"))


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import asyncio
    
    async def test():
        test_prompt = """
        è¯·åˆ†æä»¥ä¸‹äº‹ä»¶ï¼Œå¹¶è¿”å› JSON æ ¼å¼çš„é¢„æµ‹ç»“æœï¼š
        {
            "prob_yes": <0-100ä¹‹é—´çš„æ•°å­—>,
            "confidence": "low" | "medium" | "high",
            "rationale": "<ä½ çš„åˆ†æç†ç”±>"
        }
        
        äº‹ä»¶ï¼šWill Maduro be out of power in Venezuela by 2025?
        """
        
        print("ğŸ§ª æµ‹è¯• OpenRouter è°ƒç”¨...")
        print(f"å¯ç”¨æ¨¡å‹: {', '.join(get_available_models())}")
        print(f"OpenRouter å¯ç”¨: {is_openrouter_available()}")
        
        if is_openrouter_available():
            # æµ‹è¯•å•ä¸ªæ¨¡å‹
            result = await call_openrouter_model(
                "mistralai/mistral-7b-instruct",
                test_prompt
            )
            print(f"\næµ‹è¯•ç»“æœ: {result}")
        else:
            print("âš ï¸ OPENROUTER_API_KEY æœªè®¾ç½®ï¼Œæ— æ³•æµ‹è¯•")
    
    asyncio.run(test())

